[
  {
    "objectID": "02_virginia_election_project_youranalysis.html",
    "href": "02_virginia_election_project_youranalysis.html",
    "title": "Virginia Election Project",
    "section": "",
    "text": "First we’ll begin by cleaning up and joining two data sets containing info on the 2020 national election results, as well as the VA governor race.\nData available here: https://historical.elections.virginia.gov/elections/view/144567/\n\nprez_2020 <- read_csv(\"processed_data/va_2020_prez_cleaned.csv\")\n\nRows: 134 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): locality\nnum (3): biden, trump, total_votes_2021_prez\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nTaking a first look at the data\n\nhead(prez_2020) \n\n# A tibble: 6 × 4\n  locality         biden trump total_votes_2021_prez\n  <chr>            <dbl> <dbl>                 <dbl>\n1 Accomack County   7578  9172                 16962\n2 Albemarle County 42466 20804                 64657\n3 Alexandria City  66240 14544                 82508\n4 Alleghany County  2243  5859                  8203\n5 Amelia County     2411  5390                  7893\n6 Amherst County    5672 11041                 17005\n\n\nCalculating percentage of the vote\n\nprez_2020 %>% \n  mutate(\n    biden_pct = biden/total_votes_2021_prez\n  )\n\n# A tibble: 134 × 5\n   locality           biden trump total_votes_2021_prez biden_pct\n   <chr>              <dbl> <dbl>                 <dbl>     <dbl>\n 1 Accomack County     7578  9172                 16962     0.447\n 2 Albemarle County   42466 20804                 64657     0.657\n 3 Alexandria City    66240 14544                 82508     0.803\n 4 Alleghany County    2243  5859                  8203     0.273\n 5 Amelia County       2411  5390                  7893     0.305\n 6 Amherst County      5672 11041                 17005     0.334\n 7 Appomattox County   2418  6702                  9268     0.261\n 8 Arlington County  105344 22318                130699     0.806\n 9 Augusta County     10840 30714                 42278     0.256\n10 Bath County          646  1834                  2501     0.258\n# … with 124 more rows\n\n\nNow let’s do some rounding and move that decimal point\n\nprez_2020 %>% \n  mutate(\n    biden_pct = janitor::round_half_up(biden / total_votes_2021_prez * 100, 1)\n  )\n\n# A tibble: 134 × 5\n   locality           biden trump total_votes_2021_prez biden_pct\n   <chr>              <dbl> <dbl>                 <dbl>     <dbl>\n 1 Accomack County     7578  9172                 16962      44.7\n 2 Albemarle County   42466 20804                 64657      65.7\n 3 Alexandria City    66240 14544                 82508      80.3\n 4 Alleghany County    2243  5859                  8203      27.3\n 5 Amelia County       2411  5390                  7893      30.5\n 6 Amherst County      5672 11041                 17005      33.4\n 7 Appomattox County   2418  6702                  9268      26.1\n 8 Arlington County  105344 22318                130699      80.6\n 9 Augusta County     10840 30714                 42278      25.6\n10 Bath County          646  1834                  2501      25.8\n# … with 124 more rows\n\n\nCalculating the percentage of the total votes Biden and Trump respectively recieved\n\nprez_2020 <- prez_2020 %>% \n  mutate(\n    biden_pct = janitor::round_half_up(biden / total_votes_2021_prez * 100, 2),\n    trump_pct = janitor::round_half_up(trump / total_votes_2021_prez * 100, 2)\n  )\n\nhead(prez_2020)\n\n# A tibble: 6 × 6\n  locality         biden trump total_votes_2021_prez biden_pct trump_pct\n  <chr>            <dbl> <dbl>                 <dbl>     <dbl>     <dbl>\n1 Accomack County   7578  9172                 16962      44.7      54.1\n2 Albemarle County 42466 20804                 64657      65.7      32.2\n3 Alexandria City  66240 14544                 82508      80.3      17.6\n4 Alleghany County  2243  5859                  8203      27.3      71.4\n5 Amelia County     2411  5390                  7893      30.6      68.3\n6 Amherst County    5672 11041                 17005      33.4      64.9\n\n\nData now available from the state here: https://historical.elections.virginia.gov/elections/view/147466.\n\njsonfile <- \"raw_data/va_gov_json_archived.json\"\n\n#using jsonlite package function fromJSON()\nthis.content <- fromJSON(jsonfile)\n\n#dataframe from just the 6 content \ncontent_df <- as.data.frame(this.content[[6]])\n\nWhere are candidates themselves? They are “nested” inside. We’ll use unnest()to expand things.\n\n#unnest\nresults <- content_df %>%\n  unnest(cols = Candidates)\n\nhead(results)\n\n# A tibble: 6 × 9\n  Locali…¹ $Loca…² Preci…³ Preci…⁴ LastM…⁵ Ballo…⁶ Ballo…⁷ Votes Perce…⁸ Polit…⁹\n  <chr>    <chr>     <int>   <int> <chr>   <chr>     <int> <int> <chr>   <chr>  \n1 ACCOMAC… 001          19      19 2021-1… Glenn …  1   e0  7878 61.08%  Republ…\n2 ACCOMAC… 001          19      19 2021-1… Terry …  2   e0  4948 38.37%  Democr…\n3 ACCOMAC… 001          19      19 2021-1… Prince…  3   e0    67 0.52%   Libera…\n4 ACCOMAC… 001          19      19 2021-1… Write …  2.15e9     4 0.03%   Write-…\n5 ALBEMAR… 003          33      33 2021-1… Glenn …  1   e0 19141 37.21%  Republ…\n6 ALBEMAR… 003          33      33 2021-1… Terry …  2   e0 31919 62.05%  Democr…\n# … with abbreviated variable names ¹​Locality$LocalityName, ²​$LocalityCode,\n#   ³​PrecinctsReporting, ⁴​PrecinctsParticipating, ⁵​LastModified, ⁶​BallotName,\n#   ⁷​BallotOrder, ⁸​Percentage, ⁹​PoliticalParty\n\n\nUnnest again on locality\n\nresults <- results %>%\n  unnest(cols = Locality)\n\nhead(results)\n\n# A tibble: 6 × 10\n  Locali…¹ Local…² Preci…³ Preci…⁴ LastM…⁵ Ballo…⁶ Ballo…⁷ Votes Perce…⁸ Polit…⁹\n  <chr>    <chr>     <int>   <int> <chr>   <chr>     <int> <int> <chr>   <chr>  \n1 ACCOMAC… 001          19      19 2021-1… Glenn …  1   e0  7878 61.08%  Republ…\n2 ACCOMAC… 001          19      19 2021-1… Terry …  2   e0  4948 38.37%  Democr…\n3 ACCOMAC… 001          19      19 2021-1… Prince…  3   e0    67 0.52%   Libera…\n4 ACCOMAC… 001          19      19 2021-1… Write …  2.15e9     4 0.03%   Write-…\n5 ALBEMAR… 003          33      33 2021-1… Glenn …  1   e0 19141 37.21%  Republ…\n6 ALBEMAR… 003          33      33 2021-1… Terry …  2   e0 31919 62.05%  Democr…\n# … with abbreviated variable names ¹​LocalityName, ²​LocalityCode,\n#   ³​PrecinctsReporting, ⁴​PrecinctsParticipating, ⁵​LastModified, ⁶​BallotName,\n#   ⁷​BallotOrder, ⁸​Percentage, ⁹​PoliticalParty\n\n\nCleaning up the columns\n\ngov_2021 <- results %>% \n  clean_names() %>% \n  select(-precincts_reporting,\n         -precincts_participating,\n         -last_modified,\n         -ballot_order)\n\nhead(gov_2021)\n\n# A tibble: 6 × 6\n  locality_name    locality_code ballot_name          votes percentage politic…¹\n  <chr>            <chr>         <chr>                <int> <chr>      <chr>    \n1 ACCOMACK COUNTY  001           Glenn A. Youngkin     7878 61.08%     Republic…\n2 ACCOMACK COUNTY  001           Terry R. McAuliffe    4948 38.37%     Democrat…\n3 ACCOMACK COUNTY  001           Princess L. Blanding    67 0.52%      Liberati…\n4 ACCOMACK COUNTY  001           Write In                 4 0.03%      Write-In \n5 ALBEMARLE COUNTY 003           Glenn A. Youngkin    19141 37.21%     Republic…\n6 ALBEMARLE COUNTY 003           Terry R. McAuliffe   31919 62.05%     Democrat…\n# … with abbreviated variable name ¹​political_party\n\n\nReshaping the data so that it’s easier to use\n\ngov_2021 <- gov_2021 %>% \n  filter(ballot_name %in% c(\"Glenn A. Youngkin\", \"Terry R. McAuliffe\")) %>% \n  select(-locality_code,\n         -political_party)\n  \ngov_2021\n\n# A tibble: 266 × 4\n   locality_name    ballot_name        votes percentage\n   <chr>            <chr>              <int> <chr>     \n 1 ACCOMACK COUNTY  Glenn A. Youngkin   7878 61.08%    \n 2 ACCOMACK COUNTY  Terry R. McAuliffe  4948 38.37%    \n 3 ALBEMARLE COUNTY Glenn A. Youngkin  19141 37.21%    \n 4 ALBEMARLE COUNTY Terry R. McAuliffe 31919 62.05%    \n 5 ALEXANDRIA CITY  Glenn A. Youngkin  14013 24.02%    \n 6 ALEXANDRIA CITY  Terry R. McAuliffe 43866 75.20%    \n 7 ALLEGHANY COUNTY Glenn A. Youngkin   4530 74.52%    \n 8 ALLEGHANY COUNTY Terry R. McAuliffe  1518 24.97%    \n 9 AMELIA COUNTY    Glenn A. Youngkin   4720 74.19%    \n10 AMELIA COUNTY    Terry R. McAuliffe  1617 25.42%    \n# … with 256 more rows\n\n\n\ngov_2021_wide <- gov_2021 %>% \n  pivot_wider(names_from = ballot_name, values_from = c(votes, percentage))\n\ngov_2021_wide\n\n# A tibble: 133 × 5\n   locality_name     `votes_Glenn A. Youngkin` votes_Terry R. …¹ perce…² perce…³\n   <chr>                                 <int>             <int> <chr>   <chr>  \n 1 ACCOMACK COUNTY                        7878              4948 61.08%  38.37% \n 2 ALBEMARLE COUNTY                      19141             31919 37.21%  62.05% \n 3 ALEXANDRIA CITY                       14013             43866 24.02%  75.20% \n 4 ALLEGHANY COUNTY                       4530              1518 74.52%  24.97% \n 5 AMELIA COUNTY                          4720              1617 74.19%  25.42% \n 6 AMHERST COUNTY                         9731              3897 71.00%  28.43% \n 7 APPOMATTOX COUNTY                      5971              1438 80.26%  19.33% \n 8 ARLINGTON COUNTY                      21548             73013 22.63%  76.67% \n 9 AUGUSTA COUNTY                        26196              7231 77.93%  21.51% \n10 BATH COUNTY                            1539               396 79.04%  20.34% \n# … with 123 more rows, and abbreviated variable names\n#   ¹​`votes_Terry R. McAuliffe`, ²​`percentage_Glenn A. Youngkin`,\n#   ³​`percentage_Terry R. McAuliffe`\n\n\n\ngov_2021_wide <- gov_2021_wide %>% \n  clean_names()\n\nhead(gov_2021_wide)\n\n# A tibble: 6 × 5\n  locality_name    votes_glenn_a_youngkin votes_terry_r_mc_aul…¹ perce…² perce…³\n  <chr>                             <int>                  <int> <chr>   <chr>  \n1 ACCOMACK COUNTY                    7878                   4948 61.08%  38.37% \n2 ALBEMARLE COUNTY                  19141                  31919 37.21%  62.05% \n3 ALEXANDRIA CITY                   14013                  43866 24.02%  75.20% \n4 ALLEGHANY COUNTY                   4530                   1518 74.52%  24.97% \n5 AMELIA COUNTY                      4720                   1617 74.19%  25.42% \n6 AMHERST COUNTY                     9731                   3897 71.00%  28.43% \n# … with abbreviated variable names ¹​votes_terry_r_mc_auliffe,\n#   ²​percentage_glenn_a_youngkin, ³​percentage_terry_r_mc_auliffe\n\n\n\ngov_2021_wide <- gov_2021_wide %>% \n  rename(\n    youngkin = votes_glenn_a_youngkin,\n    mcauliffe = votes_terry_r_mc_auliffe,\n    pct_youngkin = percentage_glenn_a_youngkin,\n    pct_mcauliffe = percentage_terry_r_mc_auliffe\n  )\n\nhead(gov_2021_wide)\n\n# A tibble: 6 × 5\n  locality_name    youngkin mcauliffe pct_youngkin pct_mcauliffe\n  <chr>               <int>     <int> <chr>        <chr>        \n1 ACCOMACK COUNTY      7878      4948 61.08%       38.37%       \n2 ALBEMARLE COUNTY    19141     31919 37.21%       62.05%       \n3 ALEXANDRIA CITY     14013     43866 24.02%       75.20%       \n4 ALLEGHANY COUNTY     4530      1518 74.52%       24.97%       \n5 AMELIA COUNTY        4720      1617 74.19%       25.42%       \n6 AMHERST COUNTY       9731      3897 71.00%       28.43%       \n\n\n\ngov_2021_wide <- gov_2021_wide %>% \n  mutate(\n    pct_youngkin = readr::parse_number(pct_youngkin),\n    pct_mcauliffe = readr::parse_number(pct_mcauliffe)\n  )\n\nhead(gov_2021_wide)\n\n# A tibble: 6 × 5\n  locality_name    youngkin mcauliffe pct_youngkin pct_mcauliffe\n  <chr>               <int>     <int>        <dbl>         <dbl>\n1 ACCOMACK COUNTY      7878      4948         61.1          38.4\n2 ALBEMARLE COUNTY    19141     31919         37.2          62.0\n3 ALEXANDRIA CITY     14013     43866         24.0          75.2\n4 ALLEGHANY COUNTY     4530      1518         74.5          25.0\n5 AMELIA COUNTY        4720      1617         74.2          25.4\n6 AMHERST COUNTY       9731      3897         71            28.4\n\n\nPerfect. Problem solved.\n\n\n\ngov_2021_wide\n\n# A tibble: 133 × 5\n   locality_name     youngkin mcauliffe pct_youngkin pct_mcauliffe\n   <chr>                <int>     <int>        <dbl>         <dbl>\n 1 ACCOMACK COUNTY       7878      4948         61.1          38.4\n 2 ALBEMARLE COUNTY     19141     31919         37.2          62.0\n 3 ALEXANDRIA CITY      14013     43866         24.0          75.2\n 4 ALLEGHANY COUNTY      4530      1518         74.5          25.0\n 5 AMELIA COUNTY         4720      1617         74.2          25.4\n 6 AMHERST COUNTY        9731      3897         71            28.4\n 7 APPOMATTOX COUNTY     5971      1438         80.3          19.3\n 8 ARLINGTON COUNTY     21548     73013         22.6          76.7\n 9 AUGUSTA COUNTY       26196      7231         77.9          21.5\n10 BATH COUNTY           1539       396         79.0          20.3\n# … with 123 more rows\n\n\n\nprez_2020\n\n# A tibble: 134 × 6\n   locality           biden trump total_votes_2021_prez biden_pct trump_pct\n   <chr>              <dbl> <dbl>                 <dbl>     <dbl>     <dbl>\n 1 Accomack County     7578  9172                 16962      44.7      54.1\n 2 Albemarle County   42466 20804                 64657      65.7      32.2\n 3 Alexandria City    66240 14544                 82508      80.3      17.6\n 4 Alleghany County    2243  5859                  8203      27.3      71.4\n 5 Amelia County       2411  5390                  7893      30.6      68.3\n 6 Amherst County      5672 11041                 17005      33.4      64.9\n 7 Appomattox County   2418  6702                  9268      26.1      72.3\n 8 Arlington County  105344 22318                130699      80.6      17.1\n 9 Augusta County     10840 30714                 42278      25.6      72.6\n10 Bath County          646  1834                  2501      25.8      73.3\n# … with 124 more rows\n\n\nCleaning up the data sets to get them ready for the join\n\nprez_2020 <- prez_2020 %>% \n  mutate(\n    locality = str_to_upper(locality)\n  ) %>% \n  select(-total_votes_2021_prez)\n\nprez_2020\n\n# A tibble: 134 × 5\n   locality           biden trump biden_pct trump_pct\n   <chr>              <dbl> <dbl>     <dbl>     <dbl>\n 1 ACCOMACK COUNTY     7578  9172      44.7      54.1\n 2 ALBEMARLE COUNTY   42466 20804      65.7      32.2\n 3 ALEXANDRIA CITY    66240 14544      80.3      17.6\n 4 ALLEGHANY COUNTY    2243  5859      27.3      71.4\n 5 AMELIA COUNTY       2411  5390      30.6      68.3\n 6 AMHERST COUNTY      5672 11041      33.4      64.9\n 7 APPOMATTOX COUNTY   2418  6702      26.1      72.3\n 8 ARLINGTON COUNTY  105344 22318      80.6      17.1\n 9 AUGUSTA COUNTY     10840 30714      25.6      72.6\n10 BATH COUNTY          646  1834      25.8      73.3\n# … with 124 more rows\n\n\n\nanti_join(prez_2020, gov_2021_wide, by = c(\"locality\" = \"locality_name\"))\n\n# A tibble: 2 × 5\n  locality                biden   trump biden_pct trump_pct\n  <chr>                   <dbl>   <dbl>     <dbl>     <dbl>\n1 KING AND QUEEN COUNTY    1590    2450      38.6      59.5\n2 TOTALS                2413568 1962430      54.1      44  \n\n\n\nanti_join(gov_2021_wide, prez_2020, by = c(\"locality_name\" = \"locality\"))\n\n# A tibble: 1 × 5\n  locality_name       youngkin mcauliffe pct_youngkin pct_mcauliffe\n  <chr>                  <int>     <int>        <dbl>         <dbl>\n1 KING & QUEEN COUNTY     2112      1130         64.8          34.6\n\n\n\nprez_2020 <- prez_2020 %>% \n  filter(locality != \"TOTALS\") %>% \n  mutate(\n    locality = str_replace(locality, \"KING AND QUEEN\", \"KING & QUEEN\")\n  )\n\nNow joining\n\njoined_vacomparison <- inner_join(prez_2020, gov_2021_wide, by = c(\"locality\" = \"locality_name\"))\n\nhead(joined_vacomparison)\n\n# A tibble: 6 × 9\n  locality         biden trump biden_pct trump…¹ young…² mcaul…³ pct_y…⁴ pct_m…⁵\n  <chr>            <dbl> <dbl>     <dbl>   <dbl>   <int>   <int>   <dbl>   <dbl>\n1 ACCOMACK COUNTY   7578  9172      44.7    54.1    7878    4948    61.1    38.4\n2 ALBEMARLE COUNTY 42466 20804      65.7    32.2   19141   31919    37.2    62.0\n3 ALEXANDRIA CITY  66240 14544      80.3    17.6   14013   43866    24.0    75.2\n4 ALLEGHANY COUNTY  2243  5859      27.3    71.4    4530    1518    74.5    25.0\n5 AMELIA COUNTY     2411  5390      30.6    68.3    4720    1617    74.2    25.4\n6 AMHERST COUNTY    5672 11041      33.4    64.9    9731    3897    71      28.4\n# … with abbreviated variable names ¹​trump_pct, ²​youngkin, ³​mcauliffe,\n#   ⁴​pct_youngkin, ⁵​pct_mcauliffe\n\n#save results to file for next step\nsaveRDS(joined_vacomparison, here(\"processed_data\", \"joined_vacomparison.rds\"))\nwrite_csv(joined_vacomparison, here(\"processed_data\", \"joined_vacomparison.csv\"))\n\n\n\n\n\njoined_vacomparison %>% \n  mutate(\n    mc_overperform = pct_mcauliffe - biden_pct,\n    mc_overperform_5 <- if_else(mc_overperform < -5, \"Yes\", \"No\")\n  )\n\n# A tibble: 133 × 11\n   locality  biden trump biden…¹ trump…² young…³ mcaul…⁴ pct_y…⁵ pct_m…⁶ mc_ov…⁷\n   <chr>     <dbl> <dbl>   <dbl>   <dbl>   <int>   <int>   <dbl>   <dbl>   <dbl>\n 1 ACCOMAC…   7578  9172    44.7    54.1    7878    4948    61.1    38.4   -6.31\n 2 ALBEMAR…  42466 20804    65.7    32.2   19141   31919    37.2    62.0   -3.63\n 3 ALEXAND…  66240 14544    80.3    17.6   14013   43866    24.0    75.2   -5.08\n 4 ALLEGHA…   2243  5859    27.3    71.4    4530    1518    74.5    25.0   -2.37\n 5 AMELIA …   2411  5390    30.6    68.3    4720    1617    74.2    25.4   -5.13\n 6 AMHERST…   5672 11041    33.4    64.9    9731    3897    71      28.4   -4.92\n 7 APPOMAT…   2418  6702    26.1    72.3    5971    1438    80.3    19.3   -6.76\n 8 ARLINGT… 105344 22318    80.6    17.1   21548   73013    22.6    76.7   -3.93\n 9 AUGUSTA…  10840 30714    25.6    72.6   26196    7231    77.9    21.5   -4.13\n10 BATH CO…    646  1834    25.8    73.3    1539     396    79.0    20.3   -5.49\n# … with 123 more rows, 1 more variable: `mc_overperform_5 <- ...` <chr>, and\n#   abbreviated variable names ¹​biden_pct, ²​trump_pct, ³​youngkin, ⁴​mcauliffe,\n#   ⁵​pct_youngkin, ⁶​pct_mcauliffe, ⁷​mc_overperform\n\n\n\nsaveRDS(joined_vacomparison, here(\"processed_data\", \"joined_vacomparison.rds\"))\nwrite_csv(joined_vacomparison, here(\"processed_data\", \"joined_vacomparison.csv\"))\n\n\nhead(joined_vacomparison)\n\n# A tibble: 6 × 9\n  locality         biden trump biden_pct trump…¹ young…² mcaul…³ pct_y…⁴ pct_m…⁵\n  <chr>            <dbl> <dbl>     <dbl>   <dbl>   <int>   <int>   <dbl>   <dbl>\n1 ACCOMACK COUNTY   7578  9172      44.7    54.1    7878    4948    61.1    38.4\n2 ALBEMARLE COUNTY 42466 20804      65.7    32.2   19141   31919    37.2    62.0\n3 ALEXANDRIA CITY  66240 14544      80.3    17.6   14013   43866    24.0    75.2\n4 ALLEGHANY COUNTY  2243  5859      27.3    71.4    4530    1518    74.5    25.0\n5 AMELIA COUNTY     2411  5390      30.6    68.3    4720    1617    74.2    25.4\n6 AMHERST COUNTY    5672 11041      33.4    64.9    9731    3897    71      28.4\n# … with abbreviated variable names ¹​trump_pct, ²​youngkin, ³​mcauliffe,\n#   ⁴​pct_youngkin, ⁵​pct_mcauliffe\n\n\nFirst, need to join the data set with a shapefile in order to produce a map\n\nva_count_geo <- tigris::counties(state = \"VA\", resolution = \"20m\", cb = TRUE)\n\nRetrieving data for the year 2021\n\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   2%\n  |                                                                            \n  |==                                                                    |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |======                                                                |   9%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |=========                                                             |  12%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |==========                                                            |  15%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |===============                                                       |  22%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |====================                                                  |  29%\n  |                                                                            \n  |=====================                                                 |  31%\n  |                                                                            \n  |=======================                                               |  32%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |=========================                                             |  35%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |===========================                                           |  38%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |============================                                          |  41%\n  |                                                                            \n  |=============================                                         |  41%\n  |                                                                            \n  |===============================================                       |  68%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |======================================================================| 100%\n\nva_count_geo$NAMELSAD <- toupper(va_count_geo$NAMELSAD)\n\nva_elect_sf <- va_count_geo %>% \n  left_join(. , joined_vacomparison, by=c(\"NAMELSAD\"=\"locality\"))\n\nNext, I’ll customize the labels and pop-ups for the maps so they look cleaner\n\nmylabel1 <- glue::glue(\"{va_elect_sf$NAMELSAD} {va_elect_sf$biden_pct}\")\n\nmylabel2 <- glue::glue(\"{va_elect_sf$NAMELSAD} {va_elect_sf$pct_mcauliffe}\")\n\nmylabel3 <- glue::glue(\"{va_elect_sf$NAMELSAD} {va_elect_sf$trump_pct}\")\n\nmylabel4 <- glue::glue(\"{va_elect_sf$NAMELSAD} {va_elect_sf$pct_youngkin}\")\n\n\nmypopup1 <- glue::glue(\"<strong>{va_elect_sf$NAMELSAD}</strong><br />\n                      Biden Pct: {va_elect_sf$biden_pct}<br />\") %>% \n  lapply(htmltools::HTML)\n\nmypopup2 <- glue::glue(\"<strong>{va_elect_sf$NAMELSAD}</strong><br />\n                      McAuliffe Pct: {va_elect_sf$pct_mcauliffe}<br />\") %>% \n  lapply(htmltools::HTML)\n\nmypopup3 <- glue::glue(\"<strong>{va_elect_sf$NAMELSAD}</strong><br />\n                      Trump Pct: {va_elect_sf$trump_pct}<br />\") %>% \n  lapply(htmltools::HTML)\n\nmypopup4 <- glue::glue(\"<strong>{va_elect_sf$NAMELSAD}</strong><br />\n                      Youngkin Pct: {va_elect_sf$pct_youngkin}<br />\") %>% \n  lapply(htmltools::HTML)\n\nNow I’ll create each map and clean them up to get them ready for comparison\n\nbiden_map = mapview(va_elect_sf, zcol = \"biden_pct\",\n                    col.regions = RColorBrewer::brewer.pal(9, \"Blues\"), \n                    alpha.regions = 1,\n                    legend = FALSE,\n                    popup = mypopup1,\n                    label = mylabel1)\n\nWarning: Found less unique colors (9) than unique zcol values (129)! \nInterpolating color vector to match number of zcol values.\n\n\n\nmcauliffe_map = mapview(va_elect_sf, zcol = \"pct_mcauliffe\",\n                        col.regions = RColorBrewer::brewer.pal(9, \"Blues\"), \n                        alpha.regions = 1,\n                        legend = FALSE,\n                        popup = mypopup2,\n                        label = mylabel2)\n\nWarning: Found less unique colors (9) than unique zcol values (132)! \nInterpolating color vector to match number of zcol values.\n\n\n\ntrump_map = mapview(va_elect_sf, zcol = \"trump_pct\",\n                    col.regions = RColorBrewer::brewer.pal(9, \"Reds\"), \n                    alpha.regions = 1,\n                    legend = FALSE,\n                    popup = mypopup3, \n                    label = mylabel3)\n\nWarning: Found less unique colors (9) than unique zcol values (129)! \nInterpolating color vector to match number of zcol values.\n\n\n\nyoungkin_map = mapview(va_elect_sf, zcol = \"pct_youngkin\",\n                       col.regions = RColorBrewer::brewer.pal(9, \"Reds\"), \n                       alpha.regions = 1,\n                       legend = FALSE,\n                       popup = mypopup4,\n                       label = mylabel4)\n\nWarning: Found less unique colors (9) than unique zcol values (130)! \nInterpolating color vector to match number of zcol values.\n\n\nCustomizing the labels on the map\n\n\n\nNow let’s take a look at the maps. First we’ll find the McAuliffe and Youngkin maps side by side, then the Biden and Trump maps. What we’re seeing in each map is a percentage of the total votes that each candidate received.\n\nsync(youngkin_map, mcauliffe_map)\n\n\n\n\n\n\n\n\n\n\n\n\n\nsync(trump_map, biden_map)\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also see how Biden and McAuliffe, and Trump and Youngkin, compare to each other by district, and if there is a noticeable different\n\nbiden_map | mcauliffe_map\n\n\n\n\n\n\ntrump_map | youngkin_map\n\n\n\n\n\n\n# joined_vacomparison %>% \n#   arrange(desc(biden_pct)) %>% \n#   head(15) %>% \n#   ggplot(aes(x = locality, y = biden_pct)) + \n#   geom_col(color = \"black\", fill = \"#CDBFF5\") +\n#   coord_flip() + \n#   scale_y_continuous(name = \"Pct of Votes to Biden by County\") +\n#   scale_x_discrete(name = \"County\") +\n#   theme_clean() +\n#   labs(title = \"Voter Turnout in US Election\", \n#        subtitle = \"2020 General Election\",\n#        caption = \"Source: USA\") +\n#   theme(axis.text.y = element_text(angle = 45))\n\n\n# \n# joined_vacomparison %>% \n#   arrange(desc(trump_pct)) %>% \n#   head(15) %>% \n#   ggplot(aes(x = locality, y = trump_pct)) + \n#   geom_col(color = \"black\", fill = \"#CDBFF5\") +\n#   coord_flip() + \n#   scale_y_continuous(name = \"Pct of Votes to Trump by County\") +\n#   scale_x_discrete(name = \"County\") +\n#   theme_clean() +\n#   labs(title = \"Voter Turnout in US Election\", \n#        subtitle = \"2020 General Election\",\n#        caption = \"Source: USA\") +\n#   theme(axis.text.y = element_text(angle = 45))\n\n\n# joined_vacomparison %>% \n#   arrange(desc(pct_mcauliffe)) %>% \n#   head(15) %>% \n#   ggplot(aes(x = locality, y = pct_mcauliffe)) + \n#   geom_col(color = \"black\", fill = \"#C2F3BE\") +\n#   coord_flip() + \n#   scale_y_continuous(name = \"Pct of Votes to McAuliffe by County\") +\n#   scale_x_discrete(name = \"County\") +\n#   theme_clean() +\n#   labs(title = \"Voter Turnout in VA Election\", \n#        subtitle = \"2020 VA Governor Election\",\n#        caption = \"Source: USA\") +\n#   theme(axis.text.y = element_text(angle = 45))\n\n\n# joined_vacomparison %>% \n#   arrange(desc(pct_youngkin)) %>% \n#   head(15) %>% \n#   ggplot(aes(x = locality, y = pct_youngkin)) + \n#   geom_col(color = \"black\", fill = \"#C2F3BE\") +\n#   coord_flip() + \n#   scale_y_continuous(name = \"Pct of Votes to Youngkin by County\") +\n#   scale_x_discrete(name = \"County\") +\n#   theme_clean() +\n#   labs(title = \"Voter Turnout in VA Election\", \n#        subtitle = \"2020 VA Governor Election\",\n#        caption = \"Source: USA\") +\n#   theme(axis.text.y = element_text(angle = 45))"
  },
  {
    "objectID": "map.html",
    "href": "map.html",
    "title": "R Visualization Walkthrough",
    "section": "",
    "text": "Here I will be taking you through how I am creating an interactive map displaying the median income in Massachusetts, using census data.\n\nknitr::opts_chunk$set(echo = TRUE)\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.1.8\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\nlibrary(tigris)\n\nTo enable caching of data, set `options(tigris_use_cache = TRUE)`\nin your R script or .Rprofile.\n\nlibrary(sf)\n\nLinking to GEOS 3.8.0, GDAL 3.0.4, PROJ 6.3.1; sf_use_s2() is TRUE\n\nlibrary(tidycensus)\nlibrary(htmltools)\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(here)\n\nhere() starts at /cloud/project\n\nlibrary(mapview)\nlibrary(leafsync)\nlibrary(leaflet.extras2)\n\nLoading required package: leaflet\n\noptions(tigris_class = \"sf\")"
  },
  {
    "objectID": "map.html#step-1",
    "href": "map.html#step-1",
    "title": "R Visualization Walkthrough",
    "section": "Step #1",
    "text": "Step #1\n\nFirst, I will be coding a few variables of interest. We will be specifically analyzing the median income variable.\n\nmyvars <- c(totalpop = \"B01003_001\",\n            medincome = \"B19013_001\",\n            medage = \"B01002_001\"\n)"
  },
  {
    "objectID": "map.html#step-2",
    "href": "map.html#step-2",
    "title": "R Visualization Walkthrough",
    "section": "Step #2",
    "text": "Step #2\n\nThen, I will retrieve the data from the American Community Survey feature, using tidycensus in R.\n\nma_counties_withgeo\n\nSimple feature collection with 14 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -73.50814 ymin: 41.23796 xmax: -69.92839 ymax: 42.88659\nGeodetic CRS:  NAD83\nFirst 10 features:\n   GEOID                             NAME totalpopE totalpopM medincomeE\n1  25017  Middlesex County, Massachusetts   1623411        NA     111790\n2  25005    Bristol County, Massachusetts    576070        NA      74290\n3  25015  Hampshire County, Massachusetts    161810        NA      76959\n4  25025    Suffolk County, Massachusetts    792647        NA      80260\n5  25023   Plymouth County, Massachusetts    527602        NA      98190\n6  25027  Worcester County, Massachusetts    856858        NA      81660\n7  25009      Essex County, Massachusetts    804598        NA      86684\n8  25001 Barnstable County, Massachusetts    227942        NA      82619\n9  25013    Hampden County, Massachusetts    466265        NA      61310\n10 25021    Norfolk County, Massachusetts    720403        NA     112089\n   medincomeM medageE medageM                       geometry\n1        1032    38.5     0.1 MULTIPOLYGON (((-71.89877 4...\n2        1371    40.9     0.2 MULTIPOLYGON (((-70.83595 4...\n3        2504    36.7     0.2 MULTIPOLYGON (((-73.06577 4...\n4        1586    33.3     0.2 MULTIPOLYGON (((-70.93091 4...\n5        1711    42.6     0.2 MULTIPOLYGON (((-70.88335 4...\n6         987    40.2     0.2 MULTIPOLYGON (((-72.31363 4...\n7        1333    40.8     0.2 MULTIPOLYGON (((-70.58029 4...\n8        2539    53.9     0.2 MULTIPOLYGON (((-70.68698 4...\n9        1065    39.4     0.2 MULTIPOLYGON (((-73.07484 4...\n10       1589    40.7     0.2 MULTIPOLYGON (((-70.84466 4..."
  },
  {
    "objectID": "map.html#step-3",
    "href": "map.html#step-3",
    "title": "R Visualization Walkthrough",
    "section": "Step #3",
    "text": "Step #3\n\nNow I’ll just clean up the data a bit and get it prepped for the map.\n\nma_counties_withgeo <- ma_counties_withgeo %>%\n  select(-ends_with(\"M\"))\n\n\ncolnames(ma_counties_withgeo) <- sub(\"E$\", \"\", colnames(ma_counties_withgeo))"
  },
  {
    "objectID": "map.html#step-4",
    "href": "map.html#step-4",
    "title": "R Visualization Walkthrough",
    "section": "Step #4",
    "text": "Step #4\n\nAnd behold! Using mapview, below I can display an interactive map displaying the median income for each county in the state of Massachusetts.\n\nmapview(ma_counties_withgeo, zcol = \"medincome\", \n         col.regions = RColorBrewer::brewer.pal(9, \"Greens\"), \n         alpha.regions = 1)\n\nWarning: Found less unique colors (9) than unique zcol values (14)! \nInterpolating color vector to match number of zcol values.\n\n\n\n\n\n\n\n\nmypopup <- glue::glue(\"<strong>{ma_counties_withgeo$NAM}</strong><br />\n                      Total Population: {ma_counties_withgeo$totalpop}<br />\n                      Median Income: {ma_counties_withgeo$medincome}\") %>% \n  lapply(htmltools::HTML)"
  },
  {
    "objectID": "map.html#step-5",
    "href": "map.html#step-5",
    "title": "R Visualization Walkthrough",
    "section": "Step #5",
    "text": "Step #5\n\nHere is a cleaned up version of the map the utilizes a pop-up.\n\nmapview(ma_counties_withgeo, zcol = \"medincome\", \n         col.regions = RColorBrewer::brewer.pal(9, \"Greens\"), \n         alpha.regions = 1,\n         popup = mypopup)\n\nWarning: Found less unique colors (9) than unique zcol values (14)! \nInterpolating color vector to match number of zcol values."
  },
  {
    "objectID": "01_virginia_election_project_datawrangling.html",
    "href": "01_virginia_election_project_datawrangling.html",
    "title": "Virginia Election Project",
    "section": "",
    "text": "Data available here: https://historical.elections.virginia.gov/elections/view/144567/\nA little column cleaning and we’ll load in the data file.\n\nprez_2020 <- read_csv(\"processed_data/va_2020_prez_cleaned.csv\")\n\nRows: 134 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): locality\nnum (3): biden, trump, total_votes_2021_prez\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nLet’s see what we have\n\nhead(prez_2020) \n\n# A tibble: 6 × 4\n  locality         biden trump total_votes_2021_prez\n  <chr>            <dbl> <dbl>                 <dbl>\n1 Accomack County   7578  9172                 16962\n2 Albemarle County 42466 20804                 64657\n3 Alexandria City  66240 14544                 82508\n4 Alleghany County  2243  5859                  8203\n5 Amelia County     2411  5390                  7893\n6 Amherst County    5672 11041                 17005\n\n\nCalculating percentage of the vote\n\nprez_2020 %>% \n  mutate(\n    biden_pct = biden/total_votes_2021_prez\n  )\n\n# A tibble: 134 × 5\n   locality           biden trump total_votes_2021_prez biden_pct\n   <chr>              <dbl> <dbl>                 <dbl>     <dbl>\n 1 Accomack County     7578  9172                 16962     0.447\n 2 Albemarle County   42466 20804                 64657     0.657\n 3 Alexandria City    66240 14544                 82508     0.803\n 4 Alleghany County    2243  5859                  8203     0.273\n 5 Amelia County       2411  5390                  7893     0.305\n 6 Amherst County      5672 11041                 17005     0.334\n 7 Appomattox County   2418  6702                  9268     0.261\n 8 Arlington County  105344 22318                130699     0.806\n 9 Augusta County     10840 30714                 42278     0.256\n10 Bath County          646  1834                  2501     0.258\n# … with 124 more rows\n\n\nNow let’s do some rounding and move that decimal point\n\nprez_2020 %>% \n  mutate(\n    biden_pct = janitor::round_half_up(biden / total_votes_2021_prez * 100, 1)\n  )\n\n# A tibble: 134 × 5\n   locality           biden trump total_votes_2021_prez biden_pct\n   <chr>              <dbl> <dbl>                 <dbl>     <dbl>\n 1 Accomack County     7578  9172                 16962      44.7\n 2 Albemarle County   42466 20804                 64657      65.7\n 3 Alexandria City    66240 14544                 82508      80.3\n 4 Alleghany County    2243  5859                  8203      27.3\n 5 Amelia County       2411  5390                  7893      30.5\n 6 Amherst County      5672 11041                 17005      33.4\n 7 Appomattox County   2418  6702                  9268      26.1\n 8 Arlington County  105344 22318                130699      80.6\n 9 Augusta County     10840 30714                 42278      25.6\n10 Bath County          646  1834                  2501      25.8\n# … with 124 more rows\n\n\nNow trump too\n\nprez_2020 <- prez_2020 %>% \n  mutate(\n    biden_pct = janitor::round_half_up(biden / total_votes_2021_prez * 100, 2),\n    trump_pct = janitor::round_half_up(trump / total_votes_2021_prez * 100, 2)\n  )\n\nhead(prez_2020)\n\n# A tibble: 6 × 6\n  locality         biden trump total_votes_2021_prez biden_pct trump_pct\n  <chr>            <dbl> <dbl>                 <dbl>     <dbl>     <dbl>\n1 Accomack County   7578  9172                 16962      44.7      54.1\n2 Albemarle County 42466 20804                 64657      65.7      32.2\n3 Alexandria City  66240 14544                 82508      80.3      17.6\n4 Alleghany County  2243  5859                  8203      27.3      71.4\n5 Amelia County     2411  5390                  7893      30.6      68.3\n6 Amherst County    5672 11041                 17005      33.4      64.9"
  },
  {
    "objectID": "01_virginia_election_project_datawrangling.html#reshaping",
    "href": "01_virginia_election_project_datawrangling.html#reshaping",
    "title": "Virginia Election Project",
    "section": "Reshaping",
    "text": "Reshaping\nEnter pivot_wider().\nWe’ll get rid of everything we don’t need first.\n\ngov_2021 <- gov_2021 %>% \n  filter(ballot_name %in% c(\"Glenn A. Youngkin\", \"Terry R. McAuliffe\")) %>% \n  select(-locality_code,\n         -political_party)\n  \ngov_2021\n\n# A tibble: 266 × 4\n   locality_name    ballot_name        votes percentage\n   <chr>            <chr>              <int> <chr>     \n 1 ACCOMACK COUNTY  Glenn A. Youngkin   7878 61.08%    \n 2 ACCOMACK COUNTY  Terry R. McAuliffe  4948 38.37%    \n 3 ALBEMARLE COUNTY Glenn A. Youngkin  19141 37.21%    \n 4 ALBEMARLE COUNTY Terry R. McAuliffe 31919 62.05%    \n 5 ALEXANDRIA CITY  Glenn A. Youngkin  14013 24.02%    \n 6 ALEXANDRIA CITY  Terry R. McAuliffe 43866 75.20%    \n 7 ALLEGHANY COUNTY Glenn A. Youngkin   4530 74.52%    \n 8 ALLEGHANY COUNTY Terry R. McAuliffe  1518 24.97%    \n 9 AMELIA COUNTY    Glenn A. Youngkin   4720 74.19%    \n10 AMELIA COUNTY    Terry R. McAuliffe  1617 25.42%    \n# … with 256 more rows\n\n\nNow we’ll do the spreading out to reshape.\n\ngov_2021_wide <- gov_2021 %>% \n  pivot_wider(names_from = ballot_name, values_from = c(votes, percentage))\n\ngov_2021_wide\n\n# A tibble: 133 × 5\n   locality_name     `votes_Glenn A. Youngkin` votes_Terry R. …¹ perce…² perce…³\n   <chr>                                 <int>             <int> <chr>   <chr>  \n 1 ACCOMACK COUNTY                        7878              4948 61.08%  38.37% \n 2 ALBEMARLE COUNTY                      19141             31919 37.21%  62.05% \n 3 ALEXANDRIA CITY                       14013             43866 24.02%  75.20% \n 4 ALLEGHANY COUNTY                       4530              1518 74.52%  24.97% \n 5 AMELIA COUNTY                          4720              1617 74.19%  25.42% \n 6 AMHERST COUNTY                         9731              3897 71.00%  28.43% \n 7 APPOMATTOX COUNTY                      5971              1438 80.26%  19.33% \n 8 ARLINGTON COUNTY                      21548             73013 22.63%  76.67% \n 9 AUGUSTA COUNTY                        26196              7231 77.93%  21.51% \n10 BATH COUNTY                            1539               396 79.04%  20.34% \n# … with 123 more rows, and abbreviated variable names\n#   ¹​`votes_Terry R. McAuliffe`, ²​`percentage_Glenn A. Youngkin`,\n#   ³​`percentage_Terry R. McAuliffe`\n\n\nNice.\nThis is giving us some pretty long column names. we can change them after the fact using rename(). But first let’s clean the names to make it easier.\n\ngov_2021_wide <- gov_2021_wide %>% \n  clean_names()\n\nhead(gov_2021_wide)\n\n# A tibble: 6 × 5\n  locality_name    votes_glenn_a_youngkin votes_terry_r_mc_aul…¹ perce…² perce…³\n  <chr>                             <int>                  <int> <chr>   <chr>  \n1 ACCOMACK COUNTY                    7878                   4948 61.08%  38.37% \n2 ALBEMARLE COUNTY                  19141                  31919 37.21%  62.05% \n3 ALEXANDRIA CITY                   14013                  43866 24.02%  75.20% \n4 ALLEGHANY COUNTY                   4530                   1518 74.52%  24.97% \n5 AMELIA COUNTY                      4720                   1617 74.19%  25.42% \n6 AMHERST COUNTY                     9731                   3897 71.00%  28.43% \n# … with abbreviated variable names ¹​votes_terry_r_mc_auliffe,\n#   ²​percentage_glenn_a_youngkin, ³​percentage_terry_r_mc_auliffe\n\n\nNow let’s rename, and we’ll use similar names to what we had earlier in our 2021 results.\n\ngov_2021_wide <- gov_2021_wide %>% \n  rename(\n    youngkin = votes_glenn_a_youngkin,\n    mcauliffe = votes_terry_r_mc_auliffe,\n    pct_youngkin = percentage_glenn_a_youngkin,\n    pct_mcauliffe = percentage_terry_r_mc_auliffe\n  )\n\nhead(gov_2021_wide)\n\n# A tibble: 6 × 5\n  locality_name    youngkin mcauliffe pct_youngkin pct_mcauliffe\n  <chr>               <int>     <int> <chr>        <chr>        \n1 ACCOMACK COUNTY      7878      4948 61.08%       38.37%       \n2 ALBEMARLE COUNTY    19141     31919 37.21%       62.05%       \n3 ALEXANDRIA CITY     14013     43866 24.02%       75.20%       \n4 ALLEGHANY COUNTY     4530      1518 74.52%       24.97%       \n5 AMELIA COUNTY        4720      1617 74.19%       25.42%       \n6 AMHERST COUNTY       9731      3897 71.00%       28.43%       \n\n\nBingo.\nThere’s still one potential issue here. Can you see it?\nThe percentage columns are actually text values, not numbers. And they have that % sign in the text too. Let’s fix that using a handy function from the readr package, parse_number().\n\ngov_2021_wide <- gov_2021_wide %>% \n  mutate(\n    pct_youngkin = readr::parse_number(pct_youngkin),\n    pct_mcauliffe = readr::parse_number(pct_mcauliffe)\n  )\n\nhead(gov_2021_wide)\n\n# A tibble: 6 × 5\n  locality_name    youngkin mcauliffe pct_youngkin pct_mcauliffe\n  <chr>               <int>     <int>        <dbl>         <dbl>\n1 ACCOMACK COUNTY      7878      4948         61.1          38.4\n2 ALBEMARLE COUNTY    19141     31919         37.2          62.0\n3 ALEXANDRIA CITY     14013     43866         24.0          75.2\n4 ALLEGHANY COUNTY     4530      1518         74.5          25.0\n5 AMELIA COUNTY        4720      1617         74.2          25.4\n6 AMHERST COUNTY       9731      3897         71            28.4\n\n\nPerfect. Problem solved."
  },
  {
    "objectID": "01_virginia_election_project_datawrangling.html#comparing-gov-vs.-prez-results",
    "href": "01_virginia_election_project_datawrangling.html#comparing-gov-vs.-prez-results",
    "title": "Virginia Election Project",
    "section": "Comparing gov vs. prez results",
    "text": "Comparing gov vs. prez results\nNow that things are join, let’s actually go ahead and start making columns to compare the two elections and how the candidates did this time compared with last time.\nWhere should we go from here….? Give it a shot…\n\njoined_vacomparison %>% \n  mutate(\n    mc_overperform = pct_mcauliffe - biden_pct,\n    mc_overperform_5 <- if_else(mc_overperform < -5, \"Yes\", \"No\")\n  )\n\n# A tibble: 133 × 11\n   locality  biden trump biden…¹ trump…² young…³ mcaul…⁴ pct_y…⁵ pct_m…⁶ mc_ov…⁷\n   <chr>     <dbl> <dbl>   <dbl>   <dbl>   <int>   <int>   <dbl>   <dbl>   <dbl>\n 1 ACCOMAC…   7578  9172    44.7    54.1    7878    4948    61.1    38.4   -6.31\n 2 ALBEMAR…  42466 20804    65.7    32.2   19141   31919    37.2    62.0   -3.63\n 3 ALEXAND…  66240 14544    80.3    17.6   14013   43866    24.0    75.2   -5.08\n 4 ALLEGHA…   2243  5859    27.3    71.4    4530    1518    74.5    25.0   -2.37\n 5 AMELIA …   2411  5390    30.6    68.3    4720    1617    74.2    25.4   -5.13\n 6 AMHERST…   5672 11041    33.4    64.9    9731    3897    71      28.4   -4.92\n 7 APPOMAT…   2418  6702    26.1    72.3    5971    1438    80.3    19.3   -6.76\n 8 ARLINGT… 105344 22318    80.6    17.1   21548   73013    22.6    76.7   -3.93\n 9 AUGUSTA…  10840 30714    25.6    72.6   26196    7231    77.9    21.5   -4.13\n10 BATH CO…    646  1834    25.8    73.3    1539     396    79.0    20.3   -5.49\n# … with 123 more rows, 1 more variable: `mc_overperform_5 <- ...` <chr>, and\n#   abbreviated variable names ¹​biden_pct, ²​trump_pct, ³​youngkin, ⁴​mcauliffe,\n#   ⁵​pct_youngkin, ⁶​pct_mcauliffe, ⁷​mc_overperform\n\n\n\nsaveRDS(joined_vacomparison, here(\"processed_data\", \"joined_vacomparison.rds\"))\nwrite_csv(joined_vacomparison, here(\"processed_data\", \"joined_vacomparison.csv\"))"
  },
  {
    "objectID": "portfolio.html",
    "href": "portfolio.html",
    "title": "Articles Portfolio",
    "section": "",
    "text": "As a student journalist, I have conducted countless interviews in order to produce original reporting on the issues most affecting our communities—whether within the media itself, or during social phenomenon such as ‘Striketober.’ Below is a sample article about Striketober, which I was able to write by interviewing public servants in the DMV area. I have also linked my portfolios in MediaFile and the GW Hatchet."
  },
  {
    "objectID": "portfolio.html#mediafile-articles",
    "href": "portfolio.html#mediafile-articles",
    "title": "Articles Portfolio",
    "section": "MediaFile Articles",
    "text": "MediaFile Articles\nWhile at MediaFileDC, a student run online paper, I I conducted original reporting by speaking to various academics and experts while covering stories on the international beat. At MediaFile, the goal for reporters is to find stories with some sort of media lens—for example, my stories ranged from the Western media coverage of Afghan women, to the media scrutiny Meghan Markle faced from the UK press."
  },
  {
    "objectID": "portfolio.html#gw-hatchet-articles",
    "href": "portfolio.html#gw-hatchet-articles",
    "title": "Articles Portfolio",
    "section": "GW Hatchet Articles",
    "text": "GW Hatchet Articles\nAt The Hatchet, I covered two stories on campus involving the implentation of GW’s u-pass program, and the student and university responses to an assault, interviewing several students in the process."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "More About Me",
    "section": "",
    "text": "My name is Samiha Farooqi, and I am currently studying data science and history at The George Washington University. In my courses, I’ve utilized data visualization and data analytics to complement my research into social phenomena and issues—for example, I analyzed the social impacts of the ‘Striketober’ events in the Fall of 2021. And in a different final project in one of my data visualization classes, I attempted to answer the following question: in what ways has the average American fared over the course of the COVID-19 pandemic? Using a series of maps, graphs, and statistical figures derived from several data sets—such as the American Community Survey—I analyzed the pandemic’s impact on poverty, and what factors contributed to those changes. It is this sort of work that lies at the intersection of data science and social research that I’m most interested in."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Samiha Farooqi",
    "section": "",
    "text": "Hi, I’m Samiha, and I’m a history and data science double major\nat the George Washington University in Washington, D.C."
  },
  {
    "objectID": "va_project.html",
    "href": "va_project.html",
    "title": "Virginia Election Project",
    "section": "",
    "text": "First we’ll begin by cleaning up and joining two data sets containing info on the 2020 national election results, as well as the VA governor race.\nData available here: https://historical.elections.virginia.gov/elections/view/144567/\n\nprez_2020 <- read_csv(\"processed_data/va_2020_prez_cleaned.csv\")\n\nRows: 134 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): locality\nnum (3): biden, trump, total_votes_2021_prez\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nTaking a first look at the data\n\nhead(prez_2020) \n\n# A tibble: 6 × 4\n  locality         biden trump total_votes_2021_prez\n  <chr>            <dbl> <dbl>                 <dbl>\n1 Accomack County   7578  9172                 16962\n2 Albemarle County 42466 20804                 64657\n3 Alexandria City  66240 14544                 82508\n4 Alleghany County  2243  5859                  8203\n5 Amelia County     2411  5390                  7893\n6 Amherst County    5672 11041                 17005\n\n\nCalculating percentage of the vote\n\nprez_2020 %>% \n  mutate(\n    biden_pct = biden/total_votes_2021_prez\n  )\n\n# A tibble: 134 × 5\n   locality           biden trump total_votes_2021_prez biden_pct\n   <chr>              <dbl> <dbl>                 <dbl>     <dbl>\n 1 Accomack County     7578  9172                 16962     0.447\n 2 Albemarle County   42466 20804                 64657     0.657\n 3 Alexandria City    66240 14544                 82508     0.803\n 4 Alleghany County    2243  5859                  8203     0.273\n 5 Amelia County       2411  5390                  7893     0.305\n 6 Amherst County      5672 11041                 17005     0.334\n 7 Appomattox County   2418  6702                  9268     0.261\n 8 Arlington County  105344 22318                130699     0.806\n 9 Augusta County     10840 30714                 42278     0.256\n10 Bath County          646  1834                  2501     0.258\n# … with 124 more rows\n\n\nNow let’s do some rounding and move that decimal point\n\nprez_2020 %>% \n  mutate(\n    biden_pct = janitor::round_half_up(biden / total_votes_2021_prez * 100, 1)\n  )\n\n# A tibble: 134 × 5\n   locality           biden trump total_votes_2021_prez biden_pct\n   <chr>              <dbl> <dbl>                 <dbl>     <dbl>\n 1 Accomack County     7578  9172                 16962      44.7\n 2 Albemarle County   42466 20804                 64657      65.7\n 3 Alexandria City    66240 14544                 82508      80.3\n 4 Alleghany County    2243  5859                  8203      27.3\n 5 Amelia County       2411  5390                  7893      30.5\n 6 Amherst County      5672 11041                 17005      33.4\n 7 Appomattox County   2418  6702                  9268      26.1\n 8 Arlington County  105344 22318                130699      80.6\n 9 Augusta County     10840 30714                 42278      25.6\n10 Bath County          646  1834                  2501      25.8\n# … with 124 more rows\n\n\nCalculating the percentage of the total votes Biden and Trump respectively recieved\n\nprez_2020 <- prez_2020 %>% \n  mutate(\n    biden_pct = janitor::round_half_up(biden / total_votes_2021_prez * 100, 2),\n    trump_pct = janitor::round_half_up(trump / total_votes_2021_prez * 100, 2)\n  )\n\nhead(prez_2020)\n\n# A tibble: 6 × 6\n  locality         biden trump total_votes_2021_prez biden_pct trump_pct\n  <chr>            <dbl> <dbl>                 <dbl>     <dbl>     <dbl>\n1 Accomack County   7578  9172                 16962      44.7      54.1\n2 Albemarle County 42466 20804                 64657      65.7      32.2\n3 Alexandria City  66240 14544                 82508      80.3      17.6\n4 Alleghany County  2243  5859                  8203      27.3      71.4\n5 Amelia County     2411  5390                  7893      30.6      68.3\n6 Amherst County    5672 11041                 17005      33.4      64.9\n\n\nData now available from the state here: https://historical.elections.virginia.gov/elections/view/147466.\n\njsonfile <- \"raw_data/va_gov_json_archived.json\"\n\n#using jsonlite package function fromJSON()\nthis.content <- fromJSON(jsonfile)\n\n#dataframe from just the 6 content \ncontent_df <- as.data.frame(this.content[[6]])\n\nWhere are candidates themselves? They are “nested” inside. We’ll use unnest()to expand things.\n\n#unnest\nresults <- content_df %>%\n  unnest(cols = Candidates)\n\nhead(results)\n\n# A tibble: 6 × 9\n  Locali…¹ $Loca…² Preci…³ Preci…⁴ LastM…⁵ Ballo…⁶ Ballo…⁷ Votes Perce…⁸ Polit…⁹\n  <chr>    <chr>     <int>   <int> <chr>   <chr>     <int> <int> <chr>   <chr>  \n1 ACCOMAC… 001          19      19 2021-1… Glenn …  1   e0  7878 61.08%  Republ…\n2 ACCOMAC… 001          19      19 2021-1… Terry …  2   e0  4948 38.37%  Democr…\n3 ACCOMAC… 001          19      19 2021-1… Prince…  3   e0    67 0.52%   Libera…\n4 ACCOMAC… 001          19      19 2021-1… Write …  2.15e9     4 0.03%   Write-…\n5 ALBEMAR… 003          33      33 2021-1… Glenn …  1   e0 19141 37.21%  Republ…\n6 ALBEMAR… 003          33      33 2021-1… Terry …  2   e0 31919 62.05%  Democr…\n# … with abbreviated variable names ¹​Locality$LocalityName, ²​$LocalityCode,\n#   ³​PrecinctsReporting, ⁴​PrecinctsParticipating, ⁵​LastModified, ⁶​BallotName,\n#   ⁷​BallotOrder, ⁸​Percentage, ⁹​PoliticalParty\n\n\nUnnest again on locality\n\nresults <- results %>%\n  unnest(cols = Locality)\n\nhead(results)\n\n# A tibble: 6 × 10\n  Locali…¹ Local…² Preci…³ Preci…⁴ LastM…⁵ Ballo…⁶ Ballo…⁷ Votes Perce…⁸ Polit…⁹\n  <chr>    <chr>     <int>   <int> <chr>   <chr>     <int> <int> <chr>   <chr>  \n1 ACCOMAC… 001          19      19 2021-1… Glenn …  1   e0  7878 61.08%  Republ…\n2 ACCOMAC… 001          19      19 2021-1… Terry …  2   e0  4948 38.37%  Democr…\n3 ACCOMAC… 001          19      19 2021-1… Prince…  3   e0    67 0.52%   Libera…\n4 ACCOMAC… 001          19      19 2021-1… Write …  2.15e9     4 0.03%   Write-…\n5 ALBEMAR… 003          33      33 2021-1… Glenn …  1   e0 19141 37.21%  Republ…\n6 ALBEMAR… 003          33      33 2021-1… Terry …  2   e0 31919 62.05%  Democr…\n# … with abbreviated variable names ¹​LocalityName, ²​LocalityCode,\n#   ³​PrecinctsReporting, ⁴​PrecinctsParticipating, ⁵​LastModified, ⁶​BallotName,\n#   ⁷​BallotOrder, ⁸​Percentage, ⁹​PoliticalParty\n\n\nCleaning up the columns\n\ngov_2021 <- results %>% \n  clean_names() %>% \n  select(-precincts_reporting,\n         -precincts_participating,\n         -last_modified,\n         -ballot_order)\n\nhead(gov_2021)\n\n# A tibble: 6 × 6\n  locality_name    locality_code ballot_name          votes percentage politic…¹\n  <chr>            <chr>         <chr>                <int> <chr>      <chr>    \n1 ACCOMACK COUNTY  001           Glenn A. Youngkin     7878 61.08%     Republic…\n2 ACCOMACK COUNTY  001           Terry R. McAuliffe    4948 38.37%     Democrat…\n3 ACCOMACK COUNTY  001           Princess L. Blanding    67 0.52%      Liberati…\n4 ACCOMACK COUNTY  001           Write In                 4 0.03%      Write-In \n5 ALBEMARLE COUNTY 003           Glenn A. Youngkin    19141 37.21%     Republic…\n6 ALBEMARLE COUNTY 003           Terry R. McAuliffe   31919 62.05%     Democrat…\n# … with abbreviated variable name ¹​political_party\n\n\nReshaping the data so that it’s easier to use\n\ngov_2021 <- gov_2021 %>% \n  filter(ballot_name %in% c(\"Glenn A. Youngkin\", \"Terry R. McAuliffe\")) %>% \n  select(-locality_code,\n         -political_party)\n  \ngov_2021\n\n# A tibble: 266 × 4\n   locality_name    ballot_name        votes percentage\n   <chr>            <chr>              <int> <chr>     \n 1 ACCOMACK COUNTY  Glenn A. Youngkin   7878 61.08%    \n 2 ACCOMACK COUNTY  Terry R. McAuliffe  4948 38.37%    \n 3 ALBEMARLE COUNTY Glenn A. Youngkin  19141 37.21%    \n 4 ALBEMARLE COUNTY Terry R. McAuliffe 31919 62.05%    \n 5 ALEXANDRIA CITY  Glenn A. Youngkin  14013 24.02%    \n 6 ALEXANDRIA CITY  Terry R. McAuliffe 43866 75.20%    \n 7 ALLEGHANY COUNTY Glenn A. Youngkin   4530 74.52%    \n 8 ALLEGHANY COUNTY Terry R. McAuliffe  1518 24.97%    \n 9 AMELIA COUNTY    Glenn A. Youngkin   4720 74.19%    \n10 AMELIA COUNTY    Terry R. McAuliffe  1617 25.42%    \n# … with 256 more rows\n\n\n\ngov_2021_wide <- gov_2021 %>% \n  pivot_wider(names_from = ballot_name, values_from = c(votes, percentage))\n\ngov_2021_wide\n\n# A tibble: 133 × 5\n   locality_name     `votes_Glenn A. Youngkin` votes_Terry R. …¹ perce…² perce…³\n   <chr>                                 <int>             <int> <chr>   <chr>  \n 1 ACCOMACK COUNTY                        7878              4948 61.08%  38.37% \n 2 ALBEMARLE COUNTY                      19141             31919 37.21%  62.05% \n 3 ALEXANDRIA CITY                       14013             43866 24.02%  75.20% \n 4 ALLEGHANY COUNTY                       4530              1518 74.52%  24.97% \n 5 AMELIA COUNTY                          4720              1617 74.19%  25.42% \n 6 AMHERST COUNTY                         9731              3897 71.00%  28.43% \n 7 APPOMATTOX COUNTY                      5971              1438 80.26%  19.33% \n 8 ARLINGTON COUNTY                      21548             73013 22.63%  76.67% \n 9 AUGUSTA COUNTY                        26196              7231 77.93%  21.51% \n10 BATH COUNTY                            1539               396 79.04%  20.34% \n# … with 123 more rows, and abbreviated variable names\n#   ¹​`votes_Terry R. McAuliffe`, ²​`percentage_Glenn A. Youngkin`,\n#   ³​`percentage_Terry R. McAuliffe`\n\n\n\ngov_2021_wide <- gov_2021_wide %>% \n  clean_names()\n\nhead(gov_2021_wide)\n\n# A tibble: 6 × 5\n  locality_name    votes_glenn_a_youngkin votes_terry_r_mc_aul…¹ perce…² perce…³\n  <chr>                             <int>                  <int> <chr>   <chr>  \n1 ACCOMACK COUNTY                    7878                   4948 61.08%  38.37% \n2 ALBEMARLE COUNTY                  19141                  31919 37.21%  62.05% \n3 ALEXANDRIA CITY                   14013                  43866 24.02%  75.20% \n4 ALLEGHANY COUNTY                   4530                   1518 74.52%  24.97% \n5 AMELIA COUNTY                      4720                   1617 74.19%  25.42% \n6 AMHERST COUNTY                     9731                   3897 71.00%  28.43% \n# … with abbreviated variable names ¹​votes_terry_r_mc_auliffe,\n#   ²​percentage_glenn_a_youngkin, ³​percentage_terry_r_mc_auliffe\n\n\n\ngov_2021_wide <- gov_2021_wide %>% \n  rename(\n    youngkin = votes_glenn_a_youngkin,\n    mcauliffe = votes_terry_r_mc_auliffe,\n    pct_youngkin = percentage_glenn_a_youngkin,\n    pct_mcauliffe = percentage_terry_r_mc_auliffe\n  )\n\nhead(gov_2021_wide)\n\n# A tibble: 6 × 5\n  locality_name    youngkin mcauliffe pct_youngkin pct_mcauliffe\n  <chr>               <int>     <int> <chr>        <chr>        \n1 ACCOMACK COUNTY      7878      4948 61.08%       38.37%       \n2 ALBEMARLE COUNTY    19141     31919 37.21%       62.05%       \n3 ALEXANDRIA CITY     14013     43866 24.02%       75.20%       \n4 ALLEGHANY COUNTY     4530      1518 74.52%       24.97%       \n5 AMELIA COUNTY        4720      1617 74.19%       25.42%       \n6 AMHERST COUNTY       9731      3897 71.00%       28.43%       \n\n\n\ngov_2021_wide <- gov_2021_wide %>% \n  mutate(\n    pct_youngkin = readr::parse_number(pct_youngkin),\n    pct_mcauliffe = readr::parse_number(pct_mcauliffe)\n  )\n\nhead(gov_2021_wide)\n\n# A tibble: 6 × 5\n  locality_name    youngkin mcauliffe pct_youngkin pct_mcauliffe\n  <chr>               <int>     <int>        <dbl>         <dbl>\n1 ACCOMACK COUNTY      7878      4948         61.1          38.4\n2 ALBEMARLE COUNTY    19141     31919         37.2          62.0\n3 ALEXANDRIA CITY     14013     43866         24.0          75.2\n4 ALLEGHANY COUNTY     4530      1518         74.5          25.0\n5 AMELIA COUNTY        4720      1617         74.2          25.4\n6 AMHERST COUNTY       9731      3897         71            28.4\n\n\nPerfect. Problem solved.\n\n\n\ngov_2021_wide\n\n# A tibble: 133 × 5\n   locality_name     youngkin mcauliffe pct_youngkin pct_mcauliffe\n   <chr>                <int>     <int>        <dbl>         <dbl>\n 1 ACCOMACK COUNTY       7878      4948         61.1          38.4\n 2 ALBEMARLE COUNTY     19141     31919         37.2          62.0\n 3 ALEXANDRIA CITY      14013     43866         24.0          75.2\n 4 ALLEGHANY COUNTY      4530      1518         74.5          25.0\n 5 AMELIA COUNTY         4720      1617         74.2          25.4\n 6 AMHERST COUNTY        9731      3897         71            28.4\n 7 APPOMATTOX COUNTY     5971      1438         80.3          19.3\n 8 ARLINGTON COUNTY     21548     73013         22.6          76.7\n 9 AUGUSTA COUNTY       26196      7231         77.9          21.5\n10 BATH COUNTY           1539       396         79.0          20.3\n# … with 123 more rows\n\n\n\nprez_2020\n\n# A tibble: 134 × 6\n   locality           biden trump total_votes_2021_prez biden_pct trump_pct\n   <chr>              <dbl> <dbl>                 <dbl>     <dbl>     <dbl>\n 1 Accomack County     7578  9172                 16962      44.7      54.1\n 2 Albemarle County   42466 20804                 64657      65.7      32.2\n 3 Alexandria City    66240 14544                 82508      80.3      17.6\n 4 Alleghany County    2243  5859                  8203      27.3      71.4\n 5 Amelia County       2411  5390                  7893      30.6      68.3\n 6 Amherst County      5672 11041                 17005      33.4      64.9\n 7 Appomattox County   2418  6702                  9268      26.1      72.3\n 8 Arlington County  105344 22318                130699      80.6      17.1\n 9 Augusta County     10840 30714                 42278      25.6      72.6\n10 Bath County          646  1834                  2501      25.8      73.3\n# … with 124 more rows\n\n\nCleaning up the data sets to get them ready for the join\n\nprez_2020 <- prez_2020 %>% \n  mutate(\n    locality = str_to_upper(locality)\n  ) %>% \n  select(-total_votes_2021_prez)\n\nprez_2020\n\n# A tibble: 134 × 5\n   locality           biden trump biden_pct trump_pct\n   <chr>              <dbl> <dbl>     <dbl>     <dbl>\n 1 ACCOMACK COUNTY     7578  9172      44.7      54.1\n 2 ALBEMARLE COUNTY   42466 20804      65.7      32.2\n 3 ALEXANDRIA CITY    66240 14544      80.3      17.6\n 4 ALLEGHANY COUNTY    2243  5859      27.3      71.4\n 5 AMELIA COUNTY       2411  5390      30.6      68.3\n 6 AMHERST COUNTY      5672 11041      33.4      64.9\n 7 APPOMATTOX COUNTY   2418  6702      26.1      72.3\n 8 ARLINGTON COUNTY  105344 22318      80.6      17.1\n 9 AUGUSTA COUNTY     10840 30714      25.6      72.6\n10 BATH COUNTY          646  1834      25.8      73.3\n# … with 124 more rows\n\n\n\nanti_join(prez_2020, gov_2021_wide, by = c(\"locality\" = \"locality_name\"))\n\n# A tibble: 2 × 5\n  locality                biden   trump biden_pct trump_pct\n  <chr>                   <dbl>   <dbl>     <dbl>     <dbl>\n1 KING AND QUEEN COUNTY    1590    2450      38.6      59.5\n2 TOTALS                2413568 1962430      54.1      44  \n\n\n\nanti_join(gov_2021_wide, prez_2020, by = c(\"locality_name\" = \"locality\"))\n\n# A tibble: 1 × 5\n  locality_name       youngkin mcauliffe pct_youngkin pct_mcauliffe\n  <chr>                  <int>     <int>        <dbl>         <dbl>\n1 KING & QUEEN COUNTY     2112      1130         64.8          34.6\n\n\n\nprez_2020 <- prez_2020 %>% \n  filter(locality != \"TOTALS\") %>% \n  mutate(\n    locality = str_replace(locality, \"KING AND QUEEN\", \"KING & QUEEN\")\n  )\n\nNow joining\n\njoined_vacomparison <- inner_join(prez_2020, gov_2021_wide, by = c(\"locality\" = \"locality_name\"))\n\nhead(joined_vacomparison)\n\n# A tibble: 6 × 9\n  locality         biden trump biden_pct trump…¹ young…² mcaul…³ pct_y…⁴ pct_m…⁵\n  <chr>            <dbl> <dbl>     <dbl>   <dbl>   <int>   <int>   <dbl>   <dbl>\n1 ACCOMACK COUNTY   7578  9172      44.7    54.1    7878    4948    61.1    38.4\n2 ALBEMARLE COUNTY 42466 20804      65.7    32.2   19141   31919    37.2    62.0\n3 ALEXANDRIA CITY  66240 14544      80.3    17.6   14013   43866    24.0    75.2\n4 ALLEGHANY COUNTY  2243  5859      27.3    71.4    4530    1518    74.5    25.0\n5 AMELIA COUNTY     2411  5390      30.6    68.3    4720    1617    74.2    25.4\n6 AMHERST COUNTY    5672 11041      33.4    64.9    9731    3897    71      28.4\n# … with abbreviated variable names ¹​trump_pct, ²​youngkin, ³​mcauliffe,\n#   ⁴​pct_youngkin, ⁵​pct_mcauliffe\n\n#save results to file for next step\nsaveRDS(joined_vacomparison, here(\"processed_data\", \"joined_vacomparison.rds\"))\nwrite_csv(joined_vacomparison, here(\"processed_data\", \"joined_vacomparison.csv\"))\n\n\n\n\n\njoined_vacomparison %>% \n  mutate(\n    mc_overperform = pct_mcauliffe - biden_pct,\n    mc_overperform_5 <- if_else(mc_overperform < -5, \"Yes\", \"No\")\n  )\n\n# A tibble: 133 × 11\n   locality  biden trump biden…¹ trump…² young…³ mcaul…⁴ pct_y…⁵ pct_m…⁶ mc_ov…⁷\n   <chr>     <dbl> <dbl>   <dbl>   <dbl>   <int>   <int>   <dbl>   <dbl>   <dbl>\n 1 ACCOMAC…   7578  9172    44.7    54.1    7878    4948    61.1    38.4   -6.31\n 2 ALBEMAR…  42466 20804    65.7    32.2   19141   31919    37.2    62.0   -3.63\n 3 ALEXAND…  66240 14544    80.3    17.6   14013   43866    24.0    75.2   -5.08\n 4 ALLEGHA…   2243  5859    27.3    71.4    4530    1518    74.5    25.0   -2.37\n 5 AMELIA …   2411  5390    30.6    68.3    4720    1617    74.2    25.4   -5.13\n 6 AMHERST…   5672 11041    33.4    64.9    9731    3897    71      28.4   -4.92\n 7 APPOMAT…   2418  6702    26.1    72.3    5971    1438    80.3    19.3   -6.76\n 8 ARLINGT… 105344 22318    80.6    17.1   21548   73013    22.6    76.7   -3.93\n 9 AUGUSTA…  10840 30714    25.6    72.6   26196    7231    77.9    21.5   -4.13\n10 BATH CO…    646  1834    25.8    73.3    1539     396    79.0    20.3   -5.49\n# … with 123 more rows, 1 more variable: `mc_overperform_5 <- ...` <chr>, and\n#   abbreviated variable names ¹​biden_pct, ²​trump_pct, ³​youngkin, ⁴​mcauliffe,\n#   ⁵​pct_youngkin, ⁶​pct_mcauliffe, ⁷​mc_overperform\n\n\n\nsaveRDS(joined_vacomparison, here(\"processed_data\", \"joined_vacomparison.rds\"))\nwrite_csv(joined_vacomparison, here(\"processed_data\", \"joined_vacomparison.csv\"))\n\n\nhead(joined_vacomparison)\n\n# A tibble: 6 × 9\n  locality         biden trump biden_pct trump…¹ young…² mcaul…³ pct_y…⁴ pct_m…⁵\n  <chr>            <dbl> <dbl>     <dbl>   <dbl>   <int>   <int>   <dbl>   <dbl>\n1 ACCOMACK COUNTY   7578  9172      44.7    54.1    7878    4948    61.1    38.4\n2 ALBEMARLE COUNTY 42466 20804      65.7    32.2   19141   31919    37.2    62.0\n3 ALEXANDRIA CITY  66240 14544      80.3    17.6   14013   43866    24.0    75.2\n4 ALLEGHANY COUNTY  2243  5859      27.3    71.4    4530    1518    74.5    25.0\n5 AMELIA COUNTY     2411  5390      30.6    68.3    4720    1617    74.2    25.4\n6 AMHERST COUNTY    5672 11041      33.4    64.9    9731    3897    71      28.4\n# … with abbreviated variable names ¹​trump_pct, ²​youngkin, ³​mcauliffe,\n#   ⁴​pct_youngkin, ⁵​pct_mcauliffe\n\n\n\nFirst, need to join the data set with a shapefile in order to produce a map\n\n\nva_count_geo$NAMELSAD <- toupper(va_count_geo$NAMELSAD)\n\nva_elect_sf <- va_count_geo %>% \n  left_join(. , joined_vacomparison, by=c(\"NAMELSAD\"=\"locality\"))\n\nNext, I’ll customize the labels and pop-ups for the maps so they look cleaner\n\nmylabel1 <- glue::glue(\"{va_elect_sf$NAMELSAD} {va_elect_sf$biden_pct}\")\n\nmylabel2 <- glue::glue(\"{va_elect_sf$NAMELSAD} {va_elect_sf$pct_mcauliffe}\")\n\nmylabel3 <- glue::glue(\"{va_elect_sf$NAMELSAD} {va_elect_sf$trump_pct}\")\n\nmylabel4 <- glue::glue(\"{va_elect_sf$NAMELSAD} {va_elect_sf$pct_youngkin}\")\n\n\nmypopup1 <- glue::glue(\"<strong>{va_elect_sf$NAMELSAD}</strong><br />\n                      Biden Pct: {va_elect_sf$biden_pct}<br />\") %>% \n  lapply(htmltools::HTML)\n\nmypopup2 <- glue::glue(\"<strong>{va_elect_sf$NAMELSAD}</strong><br />\n                      McAuliffe Pct: {va_elect_sf$pct_mcauliffe}<br />\") %>% \n  lapply(htmltools::HTML)\n\nmypopup3 <- glue::glue(\"<strong>{va_elect_sf$NAMELSAD}</strong><br />\n                      Trump Pct: {va_elect_sf$trump_pct}<br />\") %>% \n  lapply(htmltools::HTML)\n\nmypopup4 <- glue::glue(\"<strong>{va_elect_sf$NAMELSAD}</strong><br />\n                      Youngkin Pct: {va_elect_sf$pct_youngkin}<br />\") %>% \n  lapply(htmltools::HTML)\n\nNow I’ll create each map and clean them up to get them ready for comparison\n\nbiden_map = mapview(va_elect_sf, zcol = \"biden_pct\",\n                    col.regions = RColorBrewer::brewer.pal(9, \"Blues\"), \n                    alpha.regions = 1,\n                    legend = FALSE,\n                    popup = mypopup1,\n                    label = mylabel1)\n\nWarning: Found less unique colors (9) than unique zcol values (129)! \nInterpolating color vector to match number of zcol values.\n\n\n\nmcauliffe_map = mapview(va_elect_sf, zcol = \"pct_mcauliffe\",\n                        col.regions = RColorBrewer::brewer.pal(9, \"Blues\"), \n                        alpha.regions = 1,\n                        legend = FALSE,\n                        popup = mypopup2,\n                        label = mylabel2)\n\nWarning: Found less unique colors (9) than unique zcol values (132)! \nInterpolating color vector to match number of zcol values.\n\n\n\ntrump_map = mapview(va_elect_sf, zcol = \"trump_pct\",\n                    col.regions = RColorBrewer::brewer.pal(9, \"Reds\"), \n                    alpha.regions = 1,\n                    legend = FALSE,\n                    popup = mypopup3, \n                    label = mylabel3)\n\nWarning: Found less unique colors (9) than unique zcol values (129)! \nInterpolating color vector to match number of zcol values.\n\n\n\nyoungkin_map = mapview(va_elect_sf, zcol = \"pct_youngkin\",\n                       col.regions = RColorBrewer::brewer.pal(9, \"Reds\"), \n                       alpha.regions = 1,\n                       legend = FALSE,\n                       popup = mypopup4,\n                       label = mylabel4)\n\nWarning: Found less unique colors (9) than unique zcol values (130)! \nInterpolating color vector to match number of zcol values.\n\n\n\n\n\nNow let’s take a look at the maps. First we’ll find the McAuliffe and Youngkin maps side by side, then the Biden and Trump maps. What we’re seeing in each map is a percentage of the total votes that each candidate received.\n\nsync(youngkin_map, mcauliffe_map)\n\n\n\n\n\n\n\n\n\n\n\n\n\nsync(trump_map, biden_map)\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also see how Biden and McAuliffe, and Trump and Youngkin, compare to each other by district, and if there is a noticeable different\n\nbiden_map | mcauliffe_map\n\n\n\n\n\n\ntrump_map | youngkin_map"
  },
  {
    "objectID": "walkthrough.html",
    "href": "walkthrough.html",
    "title": "Sample Research Article",
    "section": "",
    "text": "Below is a writing sample, which is a formal research paper into how the pressure of grades may or may not affect a student’s writing process.\n\nA Call to Abolish Grades\n\nIntroduction:\nFor years, there has been considerable pressure on k-12 public schools across the United States to perform well on state standardized tests. Often, performance on these tests dictate the amount of state or federal funding a district receives, and how high they rank comparatively.  In my home state of Massachusetts in particular, many schools specifically prepare for the writing portion of the state standardized test, MCAS, to ensure optimal results from students. Aside from preparation for standardized tests, schools frequently teach students certain “rules’’ of writing that they’re required to follow; To do so otherwise could mean a failing grade. Given the rigidity of some of these rules of writing, as well as the general stress to perform well in school and on assessments, it’s not difficult to imagine that students may see writing in a less than positive light—especially considering that many students are forced to alter their writing habits in order to conform to whatever rules their teacher requires. This, then, is why I began my research into the composing process in writing studies. In this paper, I will explore the origins of writer’s block, as well as the extent of how standardized testing and/or rigid writing rules can add to it. \nI conducted my research by interviewing two college students: Kathy, a freshman at New York University (NYU), and Natalie, a freshman at the University of Vermont (UVM). Both of these students offer insight into their own personal relationships with writing, and the factors that influenced their respective relationships. For context, these students attended different types of high schools–Kathy attended private school from sixth through twelfth grades, while Natalie attended public school from kindergarten through twelfth grade. Furthermore, Kathy has a negative to average relationship with writing, while Natalie has a positive relationship with writing. In my research, I consider the occurrence of “rules” in each of their writing processes, as well as how their personal relationships with grades factor into their respective relationships with writing. I also analyze the school systems each student attended, and how the presence of state standardized exam preparation in school plays a role in how they approach writing. Through this, I hope to provide more clarity as to why some students may be more or less apt to write in college, the extent that k-12 education affects that, and, lastly, the way grades tend to negatively factor into it all. \n\n\nFramework:\nAside from the two interviews I conducted, I will be consulting the work of Mike Rose, as well as the work of Katherine Landau Wright. In Rose’s article,  Rigid Rules, Inflexible Plans, and the Stifling of Language: A Cognitivist Analysis of Writer’s Block, he demonstrates how the writing process is largely influenced by how a person approaches it. Rose states in his article that, “[the] students who experienced blocking were all operating either with writing rules or with planning strategies that impeded rather than enhanced the composing process.” In other words, the “blockers,” or the students who experienced writer’s block, were actively contributing to their writer’s block because of their preconceived beliefs in how the writing process must occur. It’s clear, then, that the difficulties a writer may have in the “composing process” are not simply “thinking” problems; The real issue lies more in what a writer thinks to be true about writing. In other words, what “rules” they hold onto in the writing process. To relate this back to my research, students are often taught specific rules when approaching standardized writing assessments, and writing in general. Both Kathy and Natalie mention rules and/or strategies they were taught to use in their interviews, and while they both mention that those rules aided them in ways, it’s clear they have set beliefs or routines in their respectives writing processes.\nKatharine Landou Wright et al’s work examines how middle schooler’s motivation for writing changes from 6th through 8th grade. Though their research may not seem directly applicable—as it examines a different age group—the key ideas they discuss are still relevant to my research. Wright et all states that during “testing years” in school, the writing curriculum is altered in order to prepare students specifically for the test. In those years, student’s motivation for writing tends to decrease. They specifically define “attitude toward writing” as something that “generally predicts whether a student will respond in a favorable or unfavorable manner when encountering a writing task.” Then, they discuss how students’ attitude toward writing was far less positive at the end of seventh grade–the year the specific school they study prepares for state exams. They state that, “these [negative] experiences may have been related to some combination of the method of instruction or the stress related to preparing for and completing a high-stakes writing exam.” In relation to my own research, Wright et al’s work points to the idea that exam preparation in schools could negatively affect a student’s attitude and/or general relationship with writing. For Kathy and Natalie specifically, I found that their respective relationships with writing is far more nuanced. However, it would still seem standardized testing influenced their outlook on writing in many ways.\n\n\nCan being taught highly mechanized rules of writing in k-12 schooling negatively affect a student’s attitude/motivation towards writing?\nKathy’s current relationship with writing varies depending on the kind of writing she’s doing. She mentions that, “creative writing like on my own I actually don’t mind…[but] any time when we have like a..big essay assignment...I do kind of dread it, and I put it off.” When asked more about why she tends to procrastinate larger, analytical essay assignments, she mentions specific strategies she has to follow, “I always do my introduction last..I find that writing a thesis before—I will think of something halfway through writing the paper, even if I already have an outline ready...then I’ll realize, I wanna explore that instead of whatever..I was planning beforehand. And then I have to redo the whole thing.” For Kathy, writing isn’t necessarily difficult for her, but she has these rules for herself that she follows in order to write the most successful paper she can. This would seem to constitute Rose’s definition of “blocker” behavior, as she has specific writing strategies that could prolong the writing process—but that isn’t necessarily the case. In actuality, Kathy’s rules help, rather than hinder, as they allow her to achieve higher grades. As she states herself, “going into high school, late middle school, my relationship with writing was not good because of the grades I had received.” It took being taught a set of rules/guidelines that helped her understand how to write a paper, and thus, boost her grades, to improve Kathy’s attitude towards writing. Now, as a college student, Kathy is “never too worried about the structure [when writing a paper].” What has negatively influenced her motivation to write is the existence of a word count, “I’m not somebody that just likes to drone on and on...I tend to write very concise[ly], so those sort of page and word parameters make things very difficult for me.” This, coupled with her habit of procrastinating, is the main cause of Kathy’s bouts with writer’s block—not any sort of rigid rule or strategy.\nNatalie has a different approach to writing. In terms of the rules she was taught, she mentions fairly standard rules for essay writing, such as writing an introduction paragraph with a thesis, three body paragraphs, and ending with a conclusion paragraph. Besides that, she doesn’t mention any specific strategy or rule she has for writing. In regards to MCAS writing specifically, she says, “obviously, you have to do the intro first, because you have this limited amount of space.” And as for if these kinds of rules helped or hindered her, Natalie says, “for me, I think it helped because I need..instructions, and I like specific instructions..but I think you could argue it both ways.” While some rules may have slowed her down at times, such as the introduction rule she mentions in MCAS writing, she, again, doesn’t discuss specific routines or approaches she uses, except the three body paragraph rule. Natalie’s relationship with writing is also unperturbed by any lower grades she receives, or the style of writing she has to complete, “I’ve always liked [writing] despite grades..even in eleventh grade when my english class was poetry and—I’m not a huge poet fan, but I like writing and writing poetry even though I don’t like poetry.” In other words, for Natalie, different styles or approaches to writing, or even lower grades, don’t hinder her at all. She enjoys writing and hasn’t let outside factors influence that. When asked if writing comes easy to her, Natalie responded by saying, “sometimes I would struggle, depending on what the topic is, but..I would say it comes pretty naturally to me.” Natalie is very much a “non-blocker,” and I argue a major reason for that isn’t just because she doesn’t hold onto many rigid rules or routines when approaching writing, but also because grades have never been a barrier for her. Natalie has always had a positive relationship with writing irrespective of how “harsh” of a grader a teacher she has is. By and large, rules for writing, and even grades, have little effect on Natalie’s attitude toward writing. In fact, when asked how she views her relationship with writing, she said frankly, “I love writing.”\n\n\nTo what degree does preparation for standardized testing, in particular, affect a student’s relationship with writing?\nAs mentioned earlier, Kathy attended a private school from sixth through twelfth grade. She took the writing portion of the MCAS once in the fourth grade, but other than that, her preparation for standardized testing revolved around school entrance exams, such as the SAT, and advanced placement classes in high school, such as AP English Language and Composition. Natalie, on the other hand, attended public school from kindergarten to twelfth grade. She took MCAS every year from third grade through tenth grades, and took the writing portion of the exam in fourth, seventh, and tenth grades. Outside of school, she also prepared for school entrance exams. As such, Kathy and Natalie have different experiences when it comes to standardized test preparation, and school in general. Kathy somewhat remembers being taught how to approach MCAS, and mentions how her teachers would say, “you need to..do it like this, you should do it like [that].” While vague, it gets to the point that Kathy, as mainly a private school student, wasn’t shaped much by state standardized exam preparation. Conversely, Natalie has far more to say about preparation for MCAS, \nI specifically remember I like to organize out my writing before I like, start for the long comp for example, so I remember—and again, I’m really bad at topic sentences, so like the topic sentences were always the hardest part for me, but then once like I did like the intro—because obviously, you have to do the intro first, because you have this limited amount of space and stuff, so I would do the intro frist, then the body paragraphs, and then the conclusion. And we were allowed to use quotes, but we really had to like explain—oh, another thing, in the body paragraphs, they would always say, like do your..do your topic sentence, and then your like reasons for whatever you’re writing about, and then you have to analyze them. Like the most important part was to analyze and then conclude.\nWhile for Natalie, these approaches helped her more than hindered her, I argue it’s still important to highlight these experiences to better understand how there is a fundamental difference in how Kathy and Natalie were taught to approach writing. Kathy’s experiences, in middle school in particular, revolve more around approaches or strategies she was taught to specifically help her learn how to write. Whereas, Natalie was taught how to write for MCAS specifically—at least from third grade through tenth grade. Only after tenth grade did the writing curriculum have more freedom, as MCAS isn’t administered past that grade level. \nWith that in mind, I argue that the main differences in Kathy and Natalie’s attitudes toward writing has to do with their educational histories, as well as how they view, and respond to, grades. I will specifically stress that their outlook on grades is extremely important in how they approach writing, because while they can—and have—been able to learn different and less rigid rules when approaching writing, their respective relationships with grades has continually shaped how they then view their relationships with writing. As mentioned earlier, Kathy was taught a far more relaxed approach to writing, especially in middle school. She mentions how in sixth grade, her teacher had told them, “he was like write about this and..he didn’t really tell us how to do it, didn’t say what we were supposed to be doing.” For Kathy specifically, this proved to be detrimental because she needs strategies and guidelines in order to understand what makes certain writing effective. As she says, this teacher, “fed [her] to the wolves.” And so, because she didn’t understand, yet, how to write, and also wasn’t scoring high enough for herself, her attitude toward writing was negative. She said, “if it hadn’t been for my poor grades in middle school….then I think that my confidence going into high school would’ve been much better.” What did help Kathy build up her “confidence” in writing, was being taught the specific functions of a paper, “my high school teacher….really mapped out..why we were doing this and why we were writing this and...how that then conveys to the audience.” These guidelines helped her achieve higher grades, which, in turn, is what began to positively shape her attitude toward writing. \nNatalie has a far different relationship with grades and writing. As stated earlier, she doesn’t view a negative grade as indicative of failure. She takes it as a learning opportunity. Writing comes more “naturally” to her, so having a teacher who is a rather harsh grader isn’t necessarily the be-all end-all for Natalie. While Kathy was taught a more relaxed approach to writing in middle school, it was the opposite for Natalie: “they were more easy-going about [rules] in high school.” Natalie was taught specific approaches to writing from elementary school onwards, as demonstrated earlier how she was able to recall various rules and strategies she was taught during preparation for MCAS in school. These strategies tended to aid her well in writing, but she didn’t seem to have a specific routine or guideline when it comes to approaching any given writing assignment. In my interview with her, she mentioned basic structural rules, such as the three body paragraph rule, but that is the extent. Ergo, I argue that her own relaxed approach to writing, coupled with her relationship with grades, is what has allowed her to maintain a consistently positive attitude toward writing. Kathy, in comparison, was largely influenced by her grades. When she was taught more comprehensive strategies in high school, she was able to apply them directly to her writing, and thus begin improving her grades. This is the key difference between Kathy and Natalie.\n\n\nConclusion:\nWhen beginning my research, I set out to explore if being taught highly mechanized rules in a student’s k-12 education could negatively affect their attitude toward writing in college. What I found, instead, is a far more nuanced situation. Therefore, it’s vital to stress that there are various factors at play here, such as educational history and the type of school a student attended for their k-12 education. Based on my own research, however, I believe that a student’s own relationship with grades can prove to be more detrimental to their writing process than anything else. As such, a different approach to grading is necessary. Though k-12 teachers don’t always have much say when it comes to the general curriculum—especially public school teachers—they still hold a tremendous amount of power when it comes to shaping a student’s attitude and relationship with writing. If, and when, possible, teachers should consider applying a different grading system, such as the labor based grading contract. In the words of Asao B. Inoue, author of Labor-Based Grading Contracts: Building Equity and Inclusion in the Compassionate Writing Classroom, a labor based grading contract is a system “that calculates final course grades purely by the labor students complete, not by any judgments of the quality of their writing.” Had Kathy been able to have a teacher in middle school who utilized this system, it could very well mean she wouldn’t have had such a turbulent relationship with writing. In general, the repercussions of a labor based grading system for students could mean that their individual relationships with writing would at least not include grades as a factor—and for many students, that’s all they need to begin looking at writing as something to continually improve rather than something they’re inherently bad at. Because, as Natalie demonstrates, possessing a relaxed attitude about grades can only help a student."
  },
  {
    "objectID": "essay1.html",
    "href": "essay1.html",
    "title": "Sample Essay",
    "section": "",
    "text": "Below is a basic academic paper analyzing the role of the IMF in the global economy, written for a global economic history class.\n\nPrivatize or Perish: The IMF’s Guide to Devastating an International Economy\nWhen an economic crisis emerges anywhere across the globe, it’s only natural for the IMF, or International Monetary Fund, to step in. That is their intended purpose—to provide temporary financial assistance when needed, and promote economic growth and stability. However, by the time the East Asian regional financial crisis broke out in the 1990s, there was already doubt amongst East Asian leaders that the neoliberal policies the IMF are known to impose would be the cure needed to fix their economic ails. This is a problem, to say the least. Due to the policy conditions included in IMF bailout packages, trust in Western dominated, global financial institutions has been embarrassingly low—to the point that countries actively avoid turning to them in times of crisis. To add insult to injury, China and India—two of the only countries that have seen substantial economic growth in the last few decades—were able to avoid the same crisis as many of their neighbors in the 90s by doing exactly what the IMF warned not to do: imposing capital controls, and disregarding the Washington Consensus. This lack of faith in global financial institutions, coupled with the IMF’s outright failure to adequately address economic crises, has contributed to an environment in which economic growth, worldwide, has stagnated. And unless the IMF finally chooses reality over ideology by focusing on restoring confidence in the system, economic growth will only continue to elude us all.\nAs Joseph Stiglitz recalls in his book, Globalization and its Discontents, leaders of the affected East Asian tigers “feared” that IMF policies would not allow them the room to properly manage their respective crises. However, they knew if they did not cooperate, the IMF would publicly “condemn” them, leading to a further withdrawal of international capital, and thus exacerbating the problem at hand. What Stiglitz points out is that these countries were, unfortunately, correct in their worries. Thailand, for example, followed the IMF’s instructions to a T. They would soon wish they hadn’t. Several years after the crisis began, Thailand had yet to see recovery—its economy was still in a recession, and its GDP was more than two percent lower than it had been prior to the crisis. At the same time, Malaysia and China were doing far better. Malaysia did not take part in any IMF program at all, despite the criticism this drew them. They handled the crisis on their own, and as a result, were able to recover much faster. Moreover, China did the exact opposite of everything the IMF said to do, allowing them to avoid the crisis completely. These kinds of results do not exactly inspire confidence in the IMF. But rather than admitting to any wrongdoing, they continue to push neoliberal monetary policies to this day.\nThe idea that the IMF is more concerned with bailing out investors rather than the people almost seems contradictory. One may be inclined to believe that no matter the amount of foreign aid bailouts, an economy can’t truly recover without trust from the public. Be that as it may, the IMF cares little for its policies impact on people, considering the wealth will (probably) trickle down anyway. The resulting socio-political impact of their legacy, in East Asia and worldwide, is profound. Predictably, crushingly austere monetary policies that come along with their aid packages have a tendency to build resentment amongst the affected populations. With such disdain towards the IMF, countries are forced to try and accumulate as many dollars in their central bank as possible in an effort to prepare for a future economic crisis all on their own—subsequently delegitimizing the IMF as a genuinely internationalist institution, and actually leaving the market worse off due to this massive glut of dollars. With this in mind, it’s vital to confront the question of who, exactly, the IMF helps—if not the people in the affected countries, or even the countries’ economies and governments, for whom does a bailout actually serve to benefit?\nSince the 1980s, economic growth has come to a slowdown around the world. Gone are the golden days of high growth, high wages, and high benefits that the Bretton Woods system delivered. Instead, nations around the globe—save for China and India—have been forced to reckon with stagflation, recession, and even outright depression. Post war institutions such as the IMF were once envisioned to be the solution to this sort of problem. However, over the last half century, it has been made abundantly clear who the IMF’s bailout strategy seeks to protect more than anyone else: investors. Consequently, as Stiglitz points out, this has led the institution to forgetting about the people “in the countries it was supposed to be helping,” and losing “sight of its original mission.” This has had a dire effect on economic growth. By choosing to focus on investors over people, trust in the IMF is virtually nonexistent—and that has severe impacts on global economic and political relations. Growth cannot be expected to come if no one has faith in their political and economic institutions. By and large, the IMF is a Western dominated institution that serves mainly to impose their Washington Consensus—neoliberal policies—without regard for nuance or people. If they actually sought to build up trust in economies within countries that are in need of aid, perhaps they may be able to salvage some sort of political legitimacy outside the United States and its allies. Unfortunately, that is unlikely to happen, leaving many countries in need with one of two options: privatize or perish."
  },
  {
    "objectID": "article1.html",
    "href": "article1.html",
    "title": "Sample Article",
    "section": "",
    "text": "Article Sample: As ‘Striketober’ Turns to ‘Strikemas,’ Where Does That Leave Ordinary Workers?\n\nAs her lunch break neared its end, Ismat Kumar rushed to head back to her office to clock back in. A healthcare worker at Kaiser Permanente in Northern Virginia, Kumar is more than used to the hustle and bustle that comes with working in medicine. In the 21 months since the COVID-19 pandemic began, however, it’s becoming unbearable.\nSince March 2020, Kumar said that Kaiser has made a number of controversial decisions for their staff. Lunch breaks have been shortened. Employees are now required to clock in and out for lunch. Overtime forms must be filled out every time a patient’s appointment runs late. Fed up, Kumar says a number of her coworkers have quit or found new jobs—only adding to the stress of those who remain.\n“Management will thank us, they’ll call us heroes—all while benefits are being taken away,” said Kumar. “They will listen to our complaints, but they won’t do anything about them,” she added.\nWhat Kumar is experiencing right now is not uncommon. As the pandemic has raged on across the nation, and around the world, millions of workers have been faced with a stifling workplace. As Joseph McCartin, a professor of U.S. Labor, Social, and Political History at Georgetown University said, “as we’re coming out of the pandemic, workers’ expectations and desires regarding their jobs have changed a lot.”\nMcCartin added that this phenomenon, called “the Great resignation,” is largely a “worker driven labor shortage.” Generally, workers are becoming more and more fed up with the conditions of their workplaces. Having constantly been called “heroes” without seeing an increase in their wages or benefits, many have either chosen to strike, or seek work elsewhere.\nThis is all occurring alongside what has been called “Striketober,” and moving into December, “Strikesmas.” According to The New York Times, more than 25,000 workers went on strike in October alone—compared to an average of about 10,000 workers in the previous three months.\n“In a lot of these cases, people are complaining about the oppressive nature of their work,” said McCartin. “And I think that really speaks to a broad shared experience that Americans have linked to the pandemic. This has led people to question whether they want to continue in the patterns that existed prior to the pandemic.”\nMaaz Ahmad, a public school teacher in Fairfax, VA, echoed similar experiences. The unions in Ahmad’s county aren’t very strong. This makes it difficult for the unions to actually make things happen. Something like a country-wide strike isn’t feasible for them to organize. Being a right-to-work state such as Virginia complicates the situation, as unions are further weakened. Still, Ahmad said, “I assure you, if we announced that we were going to strike, most teachers in our county would do so, and we would completely shut down the county.”\nWith the weakening of unions in recent decades, Rebecca Givan, a professor of Labor Studies and Employment Relations at Rutgers University, said,“it’s clear that unions provide tangibly better work for workers. And so when there are fewer unions, workers do suffer.”\nGivan also said that the presence of strikes tends to raise people’s awareness of them. Successful strikes make other workers realize that they could demand more, and receive significant wins. She added that, “in that way, strikes can be described as contagious.”\nComing out of a difficult period of online schooling paired with the lack of wages, Ahmad also said that this school year has been “difficult.” And as time goes on, he and other teachers are becoming more burnt out. “Whenever we go up the food chain and complain about salaries, that complaint is always set up above. That’s why there is such a large exodus of teachers this year who are just fed up. And many of them are looking to find other jobs and other professions, because, one, they get paid more, and two, the professional respect that they get is higher.”\nAhmad added that, “everyone needs to step up,” from higher up officials in each county, to elected officials at both the state and federal levels.\nWhat Ahmad is facing in his district is happening across the U.S., as teacher shortages are becoming increasingly dire. According to the Dept. of Labor Statistics, more than 270,000 public school teachers are projected to leave the profession between 2016 and 2026. A poll conducted by a well-known national teachers union showed that 1 and 3 teachers said it is likely they will retire or resign earlier than planned due to the pandemic.\nOne of the biggest complaints in Ahmad’s district has been a freeze on raises. “Every year, your salary is supposed to go up,” said Ahmad. “Except, in the last few years that hasn’t happened. And if you include inflation, we’ve essentially been getting pay cuts.”\nThings are “spiraling out of control,” said Ahmad. His county is directly feeling the impact of the teacher shortage. He said, “there are so many people who would be great teachers who are choosing not to join the profession because teachers aren’t being compensated fairly. We have so many openings, and we just have put a warm body in there because no one wants the job.”\nWhile workers across several industries are quitting, according to the Dept. of Labor, 30,000 public school teachers left their jobs in September alone.\nThese shortages aren’t confined to the classroom, as reported by PBS—from cafeteria workers to bus drivers, schools are experiencing shortages of all sorts of support staff. At least one school paid students to serve school lunches during the school day due to the staff.\nAs Ahmad said, students “aren’t learning” because of the lack of qualified teachers there. He also said that there are a number of goods and services that are provided from schools for students, such as “a warm meal,” and mental health services. “If schools can’t provide those, because of a lack of funding or staff, then who will?”"
  },
  {
    "objectID": "r_walkthrough.html",
    "href": "r_walkthrough.html",
    "title": "R Tutorial",
    "section": "",
    "text": "How to Retrieve ACS Data & use tmap\n\n\n\n\nSTEP #1\nFirst, we’ll begin by loading the necessary libraries: tidyverse, tidycensus, and tmap\n\nknitr::opts_chunk$set(echo = TRUE)\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.1.8\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\nlibrary(tidycensus)\nlibrary(tmap)\n\n\n\nSTEP #2\nNow we must use our census api key in order to retrieve our data. We can also set tmap to view mode.\n\ncensus_api_key(\"c9264540e1e33a3c55dacba891cde5dd6a5ebb5e\", overwrite = TRUE)\n\nTo install your API key for use in future sessions, run this function with `install = TRUE`.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\n\n\n\nSTEP #3\nNext, we will set our variables of choice. Because I’m looking at the number of people near the poverty threshold, I’m pulling the variable for Ratio Of Income To Poverty Level In The Past 12 Months\n\nmy_variables1 = c(\n  below = \"C17002_004\",\n  middle = \"C17002_005\"\n)\n\n\n\nSTEP #4\nNow that we have our variables, we can specify which acs survey we want to pull data from, and then set all the acs info to a variable—this is our data set now\n\nd = get_acs(\n  geography = \"state\",\n  variables = my_variables1, \n  year = 2019,\n  survey = \"acs1\",\n  geometry = TRUE,\n  resolution = \"20m\"\n) \n\nGetting data from the 2019 1-year ACS\n\n\nThe 1-year ACS provides data for geographies with populations of 65,000 and greater.\n\n\nDownloading feature geometry from the Census website.  To cache shapefiles for use in future sessions, set `options(tigris_use_cache = TRUE)`.\n\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |==============                                                        |  21%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |=================                                                     |  25%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |====================                                                  |  29%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |===========================                                           |  38%\n  |                                                                            \n  |==============================                                        |  42%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |========================================                              |  58%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |=================================================                     |  71%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |======================================================================| 100%\n\n\n\n\nSTEP #5\nAnd now we can make our map! Before we can have an interactive tmap, we will have to set the parameters to the map. Using the tmap package, we can specify the data we are pulling from and customize the map however we like.\n\n\n\n\n\nSTEP #6\nAnd finally, our finished map!"
  },
  {
    "objectID": "example_article.html",
    "href": "example_article.html",
    "title": "Example Breaking News Article Using Inline R Code",
    "section": "",
    "text": "Stock Drop Leaves Wallstreet Shocked\nThe Walt Disney Company suffered a major drop in stock today, leaving many experts confused. DIS, as it’s known by on the stock market, was up at 99.6499995 at closing on Monday this week. DIS remained high at opening as well today, at 94.800003. However, the stock had dropped to 92.309998 by closing, leaving experts confused.\nIn an interview with Danny Smith, an analyst at Goldman Sachs, Smith expressed total shock over this development, “you just don’t expect Disney to get hit. Every other company, fine—couldn’t care less, really. But Disney? They make children’s hearts sing. And for what?”\nSmith’s outrage, however, is not matched by other pockets of the population. Elsewhere in New York City,"
  }
]